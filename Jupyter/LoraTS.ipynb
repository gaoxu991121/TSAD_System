{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "from Utils.DataUtil import readData, readJson\n",
    "import math\n",
    "from datetime import  datetime\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "from Utils.EvalUtil import findSegment\n",
    "from Utils.PlotUtil import plotAllResult\n",
    "from importlib import import_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# 使用一个固定的种子\n",
    "set_seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "\n",
    "def parseParams():\n",
    "    parser = argparse.ArgumentParser(description='Time series anomaly detection system')\n",
    "\n",
    "    parser.add_argument('--random_seed', type=int, default=42, help='random seed')\n",
    "    parser.add_argument('--model_name', type=str, default=\"MSCRED\", help='name of model')\n",
    "    parser.add_argument('--dataset', type=str, default=\"NASA\", help=\"name of dataset,like 'NASA'\")\n",
    "    parser.add_argument('--filename', type=str, default=\"M-1\", help=\"file-name of time series \")\n",
    "    parser.add_argument('--filetype', type=str, default=\"npy\", help=\"file-type of time series\")\n",
    "\n",
    "    parser.add_argument('--channels', type=int, default=55, help=\"nums of dimension for time series\")\n",
    "\n",
    "    parser.add_argument('--epoch', type=int, default=20, help=\"num of training epoches\")\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.001, help=\"value of learning rate\")\n",
    "    parser.add_argument('--batch_size', type=int, default=128, help=\"batch size of data\")\n",
    "    parser.add_argument('--shuffle', type=bool, default=False, help=\"whether do shuffle by time window\")\n",
    "\n",
    "    args = parser.parse_args(args=[])\n",
    "\n",
    "    return args\n",
    "\n",
    "def getConfig(args):\n",
    "\n",
    "    start_time = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "    identifier = args.model_name + \"/\" + start_time\n",
    "    config = {\n",
    "        \"base_path\":\"../\",\n",
    "        \"model\": args.model_name,\n",
    "        \"dataset\":args.dataset,\n",
    "        \"filename\":args.filename,\n",
    "        \"filetype\":args.filetype,\n",
    "        \"epoch\": args.epoch,\n",
    "        \"input_size\": args.channels,\n",
    "        \"learning_rate\": args.learning_rate,\n",
    "        \"identifier\": identifier,\n",
    "        \"batch_size\": args.batch_size,\n",
    "        \"device\" :torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "        \"shuffle\":args.shuffle\n",
    "    }\n",
    "\n",
    "    model_config = readJson(path = config[\"base_path\"] + \"/Models/\"+config[\"model\"]+\"/Config.json\")\n",
    "\n",
    "    config = { **model_config[config[\"dataset\"]][config[\"filename\"]],** config }\n",
    "\n",
    "    #fix random seed\n",
    "    # fix_seed = args.random_seed\n",
    "    # torch.manual_seed(fix_seed)\n",
    "    # np.random.seed(fix_seed)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def getModel(config):\n",
    "    method = config[\"model\"]\n",
    "    module = import_module(\"Models.\"+method+\".Model\")\n",
    "    # 获取类引用\n",
    "    clazz = getattr(module, method)\n",
    "\n",
    "    # 创建类的实例\n",
    "    model = clazz(config).float()\n",
    "    # model = model_dict[method].Model(args).float()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# data_label_1 = pd.read_csv(\"../Data/SMD/label/machine-1-1.txt\",header=None)\n",
    "# data_label_1.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# data_test_1 = pd.read_csv(\"../Data/SMD/test/machine-1-1.txt\",header=None)\n",
    "# selected_columns = [1,9,10]\n",
    "# data_test_1 = data_test_1[selected_columns]\n",
    "# data_test_1.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "采用全部38个维度的数据训练的模型 5个epoch  F1: f1-score: 0.09188588366061504 100阈值:f1-score: 0.4449230769230769"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 80, 'latent_size': 14, 'window_size': 60, 'threshold': 0.5, 'batch_size': 128, 'num_layers': 2, 'num_heads': 1, 'drop_out_rate': 0.2, 'input_size': 38, 'epoch': 5, 'base_path': '../', 'model': 'TRANSFORMER', 'dataset': 'NASA', 'filename': 'M-1', 'filetype': 'npy', 'learning_rate': 0.001, 'identifier': 'TRANSFORMER/2024-07-06-10-52-07', 'device': device(type='cpu'), 'shuffle': False}\n",
      "data_train shape: (28479, 38)\n",
      "data_test shape: (28479, 38)\n",
      "model: TRANSFORMER(\n",
      "  (transformer): Transformer(\n",
      "    (encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=38, out_features=38, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=38, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=38, bias=True)\n",
      "          (norm1): LayerNorm((38,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((38,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((38,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=38, out_features=38, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=38, out_features=38, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=38, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=38, bias=True)\n",
      "          (norm1): LayerNorm((38,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((38,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((38,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((38,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=38, out_features=38, bias=True)\n",
      ")\n",
      "train epoch [1/5],\t loss = 78.82671374884421\n",
      "train epoch [2/5],\t loss = 12.871925614841048\n",
      "train epoch [3/5],\t loss = 7.214659878324233\n",
      "train epoch [4/5],\t loss = 5.08570315518454\n",
      "train epoch [5/5],\t loss = 3.8713102452791057\n",
      "anomaly score: [3.4190578e-04 2.1149698e-04 8.1076338e-05 ... 1.0378292e-03 9.7896450e-04\n",
      " 3.7670902e-03]\n",
      "f1-score: 0.4449230769230769  threshold: 0.010101010101010102\n"
     ]
    }
   ],
   "source": [
    "args = parseParams()\n",
    "args.model_name = \"TRANSFORMER\"\n",
    "config = getConfig(args=args)\n",
    "config[\"hidden_size\"] = 80\n",
    "config[\"num_layers\"] = 2\n",
    "config[\"num_heads\"] = 1\n",
    "config[\"drop_out_rate\"] = 0.2\n",
    "config[\"latent_size\"] = 14\n",
    "config[\"epoch\"] = 5\n",
    "\n",
    "\n",
    "window_size = config[\"window_size\"]\n",
    "\n",
    "\n",
    "\n",
    "#preprocess data\n",
    "label = pd.read_csv(\"../Data/SMD/label/machine-1-1.txt\",header=None).to_numpy()[window_size - 1:]\n",
    "data_test = pd.read_csv(\"../Data/SMD/test/machine-1-1.txt\",header=None).to_numpy()\n",
    "data_train = pd.read_csv(\"../Data/SMD/train/machine-1-1.txt\",header=None).to_numpy()\n",
    "\n",
    "\n",
    "config[\"input_size\"] = data_test.shape[-1]\n",
    "#get data\n",
    "print(config)\n",
    "\n",
    "print(\"data_train shape:\",data_train.shape)\n",
    "print(\"data_test shape:\", data_test.shape)\n",
    "\n",
    "device = config[\"device\"]\n",
    "\n",
    "#get model\n",
    "model = getModel(config=config).to(device)\n",
    "print(\"model:\",model)\n",
    "\n",
    "shuffle = config[\"shuffle\"]\n",
    "\n",
    "\n",
    "#train model\n",
    "model.fit(train_data= data_train,write_log=True)\n",
    "\n",
    "#get anomaly score\n",
    "# model.setThreshold(data_train,data_test,label)\n",
    "anomaly_scores1 = model.test(data_test)\n",
    "print(\"anomaly score:\",anomaly_scores1)\n",
    "#predict anomaly based on the threshold\n",
    "# threshold = model.getThreshold()\n",
    "#\n",
    "# predict_labels =  model.decide(anomaly_score=anomaly_scores,threshold=threshold,ground_truth_label=label)\n",
    "# # result = model.predictEvaluate(test_data=data_test, label = label, protocol =\"apa\" )\n",
    "# # print(result)\n",
    "#\n",
    "# # #evaluate\n",
    "# f1 = model.evaluate(predict_label=predict_labels,ground_truth_label=label,threshold=threshold,write_log=False)\n",
    "\n",
    "\n",
    "predict_labels,f1,threshold = model.getBestPredict(anomaly_score=anomaly_scores1,n_thresholds = 100,ground_truth_label=label,protocol=\"none\")\n",
    "print(\"f1-score:\", f1,\" threshold:\",threshold)\n",
    "\n",
    "#\n",
    "# #visualization\n",
    "# plot_yaxis = []\n",
    "# plot_yaxis.append(anomaly_scores1)\n",
    "# plot_yaxis.append(predict_labels)\n",
    "# plot_path = config[\"base_path\"]+\"/Plots/\"+config[\"identifier\"]\n",
    "# # 判断文件夹是否存在\n",
    "# if not os.path.exists(plot_path):\n",
    "#     # 如果文件夹不存在，则创建它\n",
    "#     os.makedirs(plot_path)\n",
    "# plotAllResult(x_axis=np.arange(len(predict_labels)), y_axises=plot_yaxis, title=\"\",\n",
    "#                 save_path=plot_path+\"/result.pdf\", segments=findSegment(label),threshold=threshold)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "采用后面27个维度的数据训练的模型 5个epoch 25阈值 f1-score: 0.09020332717190388 100阈值： f1-score: 0.24173491052471943 threshold: 0.010101010101010102\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 80, 'latent_size': 14, 'window_size': 60, 'threshold': 0.5, 'batch_size': 128, 'num_layers': 2, 'num_heads': 1, 'drop_out_rate': 0.2, 'input_size': 27, 'epoch': 5, 'base_path': '../', 'model': 'TRANSFORMER', 'dataset': 'NASA', 'filename': 'M-1', 'filetype': 'npy', 'learning_rate': 0.001, 'identifier': 'TRANSFORMER/2024-07-06-10-54-51', 'device': device(type='cpu'), 'shuffle': False}\n",
      "data_train shape: (28479, 27)\n",
      "data_test shape: (28479, 27)\n",
      "model: TRANSFORMER(\n",
      "  (transformer): Transformer(\n",
      "    (encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=27, out_features=27, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=27, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=27, bias=True)\n",
      "          (norm1): LayerNorm((27,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((27,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((27,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=27, out_features=27, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=27, out_features=27, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=27, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=27, bias=True)\n",
      "          (norm1): LayerNorm((27,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((27,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((27,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((27,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=27, out_features=27, bias=True)\n",
      ")\n",
      "train epoch [1/5],\t loss = 50.7074325922626\n",
      "train epoch [2/5],\t loss = 9.981898864889894\n",
      "train epoch [3/5],\t loss = 5.480512905581917\n",
      "train epoch [4/5],\t loss = 3.7964126312512185\n",
      "train epoch [5/5],\t loss = 3.006300299223763\n",
      "anomaly score: [0.00031528 0.00020956 0.00024394 ... 0.00120849 0.00136315 0.0103444 ]\n",
      "f1-score: 0.24173491052471943 threshold: 0.010101010101010102\n"
     ]
    }
   ],
   "source": [
    "args = parseParams()\n",
    "args.model_name = \"TRANSFORMER\"\n",
    "config = getConfig(args=args)\n",
    "config[\"hidden_size\"] = 80\n",
    "config[\"num_layers\"] = 2\n",
    "config[\"num_heads\"] = 1\n",
    "config[\"drop_out_rate\"] = 0.2\n",
    "config[\"latent_size\"] = 14\n",
    "config[\"epoch\"] = 5\n",
    "\n",
    "\n",
    "window_size = config[\"window_size\"]\n",
    "\n",
    "\n",
    "\n",
    "#preprocess data\n",
    "label = pd.read_csv(\"../Data/SMD/label/machine-1-1.txt\",header=None).to_numpy()[window_size - 1:]\n",
    "data_test = pd.read_csv(\"../Data/SMD/test/machine-1-1.txt\",header=None).to_numpy()[:,11:]\n",
    "data_train = pd.read_csv(\"../Data/SMD/train/machine-1-1.txt\",header=None).to_numpy()[:,11:]\n",
    "\n",
    "\n",
    "config[\"input_size\"] = data_test.shape[-1]\n",
    "#get data\n",
    "print(config)\n",
    "\n",
    "print(\"data_train shape:\",data_train.shape)\n",
    "print(\"data_test shape:\", data_test.shape)\n",
    "\n",
    "device = config[\"device\"]\n",
    "\n",
    "#get model\n",
    "model = getModel(config=config).to(device)\n",
    "print(\"model:\",model)\n",
    "\n",
    "shuffle = config[\"shuffle\"]\n",
    "\n",
    "\n",
    "#train model\n",
    "model.fit(train_data= data_train,write_log=True)\n",
    "\n",
    "#get anomaly score\n",
    "# model.setThreshold(data_train,data_test,label)\n",
    "anomaly_scores2 = model.test(data_test)\n",
    "print(\"anomaly score:\",anomaly_scores2)\n",
    "#predict anomaly based on the threshold\n",
    "# threshold = 0.041666666666666664\n",
    "#\n",
    "# predict_labels =  model.decide(anomaly_score=anomaly_scores,threshold=threshold,ground_truth_label=label)\n",
    "# # result = model.predictEvaluate(test_data=data_test, label = label, protocol =\"apa\" )\n",
    "# # print(result)\n",
    "#\n",
    "# # #evaluate\n",
    "# f1 = model.evaluate(predict_label=predict_labels,ground_truth_label=label,threshold=threshold,write_log=False)\n",
    "\n",
    "\n",
    "predict_labels,f1,threshold = model.getBestPredict(anomaly_score=anomaly_scores2,n_thresholds = 100,ground_truth_label=label,protocol=\"none\")\n",
    "model.save()\n",
    "print(\"f1-score:\", f1,\"threshold:\",threshold)\n",
    "\n",
    "\n",
    "# #visualization\n",
    "# plot_yaxis = []\n",
    "# plot_yaxis.append(anomaly_scores2)\n",
    "# plot_yaxis.append(predict_labels)\n",
    "# plot_path = config[\"base_path\"]+\"/Plots/\"+config[\"identifier\"]\n",
    "# # 判断文件夹是否存在\n",
    "# if not os.path.exists(plot_path):\n",
    "#     # 如果文件夹不存在，则创建它\n",
    "#     os.makedirs(plot_path)\n",
    "# plotAllResult(x_axis=np.arange(len(predict_labels)), y_axises=plot_yaxis, title=\"\",\n",
    "#                 save_path=plot_path+\"/result.pdf\", segments=findSegment(label),threshold=threshold)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRANSFORMER(\n",
      "  (transformer): Transformer(\n",
      "    (encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=27, out_features=27, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=27, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=27, bias=True)\n",
      "          (norm1): LayerNorm((27,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((27,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((27,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=27, out_features=27, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=27, out_features=27, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=27, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=27, bias=True)\n",
      "          (norm1): LayerNorm((27,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((27,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((27,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((27,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=27, out_features=27, bias=True)\n",
      ")\n",
      "train epoch [1/5],\t loss = 20.704676377749898\n",
      "train epoch [2/5],\t loss = 3.9329040169615648\n",
      "train epoch [3/5],\t loss = 3.1087396564087393\n",
      "train epoch [4/5],\t loss = 2.394735184168201\n",
      "train epoch [5/5],\t loss = 2.0152630573932098\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "model = getModel(config=config).to(device)\n",
    "model.load_state_dict(torch.load(\"../CheckPoints/TRANSFORMER/2024-07-04-15-41-55/checkpoint.pth\"))\n",
    "print(model)\n",
    "\n",
    "model.input_adpter = torch.nn.Linear(38,27)\n",
    "model.output_adpter = torch.nn.Linear(27,38)\n",
    "\n",
    "window_size = config[\"window_size\"]\n",
    "#preprocess data\n",
    "label = pd.read_csv(\"../Data/SMD/label/machine-1-1.txt\",header=None).to_numpy()[window_size - 1:]\n",
    "data_test = pd.read_csv(\"../Data/SMD/test/machine-1-1.txt\",header=None).to_numpy()\n",
    "data_train = pd.read_csv(\"../Data/SMD/train/machine-1-1.txt\",header=None).to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_loader = model.processData(data_train)\n",
    "model.train()\n",
    "lr = model.config[\"learning_rate\"]\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "# 设置余弦学习率衰减，这里的T_max是衰减周期\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=50, eta_min=1e-7)\n",
    "\n",
    "\n",
    "l = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "epoch_loss = []\n",
    "\n",
    "\n",
    "for ep in range(5):\n",
    "\n",
    "    # l1s = []\n",
    "    running_loss = 0\n",
    "    for d in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        item = d[0].to(model.divice)\n",
    "\n",
    "\n",
    "        data_adpted = model.input_adpter(item)\n",
    "        output = model(data_adpted,data_adpted[:,-1,:].unsqueeze(dim=1))\n",
    "        output = model.output_adpter(output)\n",
    "\n",
    "        loss = l(output, item[:,-1,:].unsqueeze(dim=1))\n",
    "\n",
    "\n",
    "\n",
    "        # l1s.append(torch.mean(loss).item())\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()  # 在每个epoch后更新学习率\n",
    "\n",
    "    # 计算当前epoch的平均损失\n",
    "    epoch_loss.append(running_loss / len(train_loader))\n",
    "\n",
    "    print(f'train epoch [{ep+1}/{model.epoch}],\\t loss = {epoch_loss[ep]}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00027793 0.00014188 0.00012081 ... 0.00092707 0.00104166 0.00386006]\n"
     ]
    }
   ],
   "source": [
    "from Preprocess.Normalization import minMaxScaling\n",
    "\n",
    "test_dataloader = model.processData(data_test)\n",
    "model.eval()\n",
    "score = []\n",
    "\n",
    "l = torch.nn.MSELoss(reduction='none')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for index, d in enumerate(test_dataloader):\n",
    "        item = d[0].to(model.divice)\n",
    "\n",
    "        data_adpted = model.input_adpter(item)\n",
    "        output = model(data_adpted,data_adpted[:,-1,:].unsqueeze(dim=1))\n",
    "\n",
    "        output = model.output_adpter(output)\n",
    "\n",
    "        loss = l(output[:, -1, :], item[:, -1, :])\n",
    "\n",
    "        loss = loss.sum(dim=-1)\n",
    "        if len(loss.shape) == 0:\n",
    "            loss = loss.unsqueeze(dim=0)\n",
    "\n",
    "        score.append(loss.detach().cpu())\n",
    "\n",
    "\n",
    "    score = torch.concatenate(score, dim=0).numpy()\n",
    "\n",
    "    score = minMaxScaling(data=score, min_value=score.min(), max_value=score.max(), range_max=1, range_min=0)\n",
    "\n",
    "print(score)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score: 0.4520921770770164\n",
      "threshold: 0.010101010101010102\n"
     ]
    }
   ],
   "source": [
    "# threshold = model.getThreshold()\n",
    "#\n",
    "# predict_labels =  model.decide(anomaly_score=score,threshold=threshold,ground_truth_label=label,protocol=\"none\")\n",
    "#\n",
    "# print(findSegment(predict_labels))\n",
    "# # print(result)\n",
    "#\n",
    "# # #evaluate\n",
    "# f1 = model.evaluate(predict_label=predict_labels,ground_truth_label=label,threshold=threshold,write_log=False)\n",
    "# #\n",
    "#\n",
    "predict_labels,f1,threshold = model.getBestPredict(anomaly_score=score,n_thresholds = 100,ground_truth_label=label,protocol=\"none\")\n",
    "print(\"f1-score:\", f1)\n",
    "print(\"threshold:\",threshold)\n",
    "#visualization\n",
    "# plot_yaxis = []\n",
    "# plot_yaxis.append(score)\n",
    "# plot_yaxis.append(predict_labels)\n",
    "# plot_path = config[\"base_path\"]+\"/Plots/\"+config[\"identifier\"]\n",
    "# # 判断文件夹是否存在\n",
    "# if not os.path.exists(plot_path):\n",
    "#     # 如果文件夹不存在，则创建它\n",
    "#     os.makedirs(plot_path)\n",
    "# plotAllResult(x_axis=np.arange(len(predict_labels)), y_axises=plot_yaxis, title=\"\",\n",
    "#                 save_path=plot_path+\"/result.pdf\", segments=findSegment(label),\n",
    "#                 threshold=threshold)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}