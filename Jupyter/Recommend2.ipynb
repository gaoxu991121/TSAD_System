{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a026ab01-0d5c-4d5d-9cbe-f94b49f47986",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "from importlib import import_module\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from Preprocess.Normalization import minMaxNormalization\n",
    "from Preprocess.Window import convertToSlidingWindow\n",
    "from Utils.DataUtil import readData\n",
    "from Utils.DistanceUtil import KLDivergence, Softmax, JSDivergence\n",
    "from Utils.EvalUtil import findSegment, countResult\n",
    "from Utils.LogUtil import wirteLog\n",
    "from Utils.PlotUtil import plotAllResult\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575a7d59-177a-49a5-96fc-5421aa348eec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40f4f093-cdc6-4798-82d8-4dcda9f2b2f0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def calculateSimilarity(origin_sample_list,new_sample_list,old_anomaly_scores,old_label_samples,threshold = 0.5):\n",
    "#\n",
    "#     '''\n",
    "#     计算新数据列表和旧数据列表的相似性，返回列表\n",
    "#     :param origin_sample_list: 需要比较的旧数据的样本列表,即窗口列表\n",
    "#     :param new_sample_list: 需要比较的新数据的样本列表,即窗口列表\n",
    "#     :return:返回列表格式，每个新数据样本对应的相似性最大的旧数据样本的Index以及相似性数值。 [(max_similarity_index,max_similarity)]\n",
    "#     '''\n",
    "#\n",
    "#     total_similarity = 0\n",
    "#\n",
    "#     result = []\n",
    "#     for new_index,new_sample in enumerate(new_sample_list):\n",
    "#         max_similarity = 0\n",
    "#         max_similarity_index = 0\n",
    "#         for origin_index,origin_sample in enumerate(origin_sample_list):\n",
    "#\n",
    "#             similarity = getSimilarity(origin_sample,new_sample)\n",
    "#             if similarity > max_similarity:\n",
    "#                 max_similarity = similarity\n",
    "#                 max_similarity_index = origin_index\n",
    "#\n",
    "#         total_similarity += max_similarity\n",
    "#\n",
    "#         result.append((max_similarity_index,max_similarity))\n",
    "#\n",
    "#     return result,total_similarity\n",
    "\n",
    "\n",
    "def getMatrixKey(sample):\n",
    "    first = np.mean(sample[0])\n",
    "    last = np.mean(sample[-1])\n",
    "    mean_all = np.mean(sample)\n",
    "    var_all = np.var(sample)\n",
    "\n",
    "    mean_all= np.floor(mean_all * 100)   # 先乘以10，再使用floor，然后再除以10\n",
    "    var_all = np.floor(var_all * 100)\n",
    "    last  = np.floor(last * 100)\n",
    "    first = np.floor(first * 100)\n",
    "    res = f\"{mean_all}{var_all}{last}{first}\"\n",
    "    return res.replace(\".\",\"-\")\n",
    "\n",
    "\n",
    "def getDistinctAndNum(sample_all) -> dict:\n",
    "\n",
    "    result = {}\n",
    "    for new_sample in sample_all:\n",
    "        # new_sample_flatten = new_sample.flatten()\n",
    "        key = getMatrixKey(new_sample)\n",
    "        if result.get(key) == None:\n",
    "            result[key] = countSame(new_sample,sample_all)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def unique(array_list):\n",
    "    # 获取数组形状\n",
    "    unique_arrays = {tuple(map(tuple, array)): array for array in array_list}\n",
    "\n",
    "    # 提取去重后的 NumPy 数组\n",
    "    unique_array_list = list(unique_arrays.values())\n",
    "\n",
    "    return unique_array_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7955e0ce-1eda-4481-bf27-bc712156a9a9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convertToWindow(data, window_size):\n",
    "    \"\"\"\n",
    "    stride为1，前window_size -1 个时间点的时间窗口，通过复制前面元素构成\n",
    "    \"\"\"\n",
    "    windows = []\n",
    "\n",
    "    for i, g in enumerate(data):\n",
    "        if i >= window_size:\n",
    "            w = data[i - window_size + 1:i + 1]\n",
    "        else:\n",
    "\n",
    "            w = np.concatenate([np.tile(data[0], window_size - i).reshape(window_size - i, -1), data[1:i + 1]])\n",
    "\n",
    "        windows.append(w)\n",
    "    return np.stack(windows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7af954d2-061f-4075-ada6-b761e86d9e33",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getConfigs():\n",
    "    config = {\n",
    "            \"epoch\": 2,\n",
    "            \"batch_size\": 128,\n",
    "            \"window_size\": 10,\n",
    "            \"identifier\": \"model-evaluation\",\n",
    "            \"hidden_size\": 64,\n",
    "            \"latent_size\": 32,\n",
    "            \"num_layers\": 2,\n",
    "            \"num_heads\": 1,\n",
    "            \"drop_out_rate\": 0.1,\n",
    "            \"learning_rate\": 1e-3,\n",
    "            \"patience\": 10,\n",
    "            \"mask\": False,\n",
    "            \"lambda_energy\": 0.1,\n",
    "            \"lambda_cov_diag\": 0.005,\n",
    "\n",
    "            \"num_filters\":3,\n",
    "            \"kernel_size\":3,\n",
    "\n",
    "            \"explained_var\":0.9,\n",
    "\n",
    "            \"kernel\": \"rbf\",\n",
    "            \"gamma\": \"auto\",\n",
    "            \"degree\": 3,\n",
    "            \"coef0\": 0.0,\n",
    "            \"tol\": 0.001,\n",
    "            \"cache_size\": 200,\n",
    "            \"shrinking\": True,\n",
    "            \"nu\": 0.48899475599830133,\n",
    "            \"step_max\": 5,\n",
    "\n",
    "            \"n_trees\": 100,\n",
    "            \"max_samples\": \"auto\",\n",
    "            \"max_features\": 1,\n",
    "            \"bootstrap\": False,\n",
    "            \"random_state\": 42,\n",
    "            \"verbose\": 0,\n",
    "            \"n_jobs\": 1,\n",
    "            \"contamination\": 0.5,\n",
    "\n",
    "\n",
    "            \"nz\":10,\n",
    "            \"beta\":0.5\n",
    "\n",
    "        }\n",
    "\n",
    "\n",
    "    return config\n",
    "def getModel(config):\n",
    "    method = config[\"model_name\"]\n",
    "    module = import_module(\"Models.\"+method+\".Model\")\n",
    "    # 获取类引用\n",
    "    clazz = getattr(module, method)\n",
    "\n",
    "    # 创建类的实例\n",
    "    model = clazz(config).float()\n",
    "    # model = model_dict[method].Model(args).float()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def getDatasetSplitConfig():\n",
    "    config = {\n",
    "        \"SKAB\":26322,\n",
    "        \"PMS\":53122,\n",
    "        \"DMDS\":200000,\n",
    "        \"WADI\":130000,\n",
    "        \"SWAT\":155000,\n",
    "\n",
    "    }\n",
    "    return config\n",
    "\n",
    "def checkHolderExist(path):\n",
    "    # 判断文件夹是否存在\n",
    "    if not os.path.exists(path):\n",
    "        # 如果文件夹不存在，则创建它\n",
    "        os.makedirs(path)\n",
    "\n",
    "def splitFiles(files):\n",
    "    random.shuffle(files)\n",
    "    split_index = len(files) // 3\n",
    "    return files[:split_index], files[split_index:]\n",
    "\n",
    "def convertRecToWindow(dataset = \"WADI\",window_size = 100):\n",
    "    # 分割出新旧数据后，转变数据为滑动窗口\n",
    "    mode = \"old\"\n",
    "    recom_dataset_path = \"./RecomData/\" + mode + \"/\" + dataset\n",
    "    data_files = os.listdir(recom_dataset_path + \"/train\")\n",
    "    for file in data_files:\n",
    "        writeWindowDataset(base_path=recom_dataset_path, filename=file, window_size=window_size)\n",
    "\n",
    "    mode = \"new\"\n",
    "    recom_dataset_path = \"./RecomData/\" + mode + \"/\" + dataset\n",
    "    data_files = os.listdir(recom_dataset_path + \"/train\")\n",
    "    for file in data_files:\n",
    "        writeWindowDataset(base_path=recom_dataset_path, filename=file, window_size=window_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0c9c74-d6f4-4fe6-bfc4-77c04c3aa148",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41367e13-ad5a-4b76-bb5e-6f7e8cd27cee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def processWADI(dataset,step):\n",
    "\n",
    "    dataset_split_config = getDatasetSplitConfig()\n",
    "    dataset_path = \"./Data/\" + dataset\n",
    "    if step == 1:\n",
    "\n",
    "\n",
    "        savepath_train_old = \"./RecomData/old/\" + dataset + \"/train\"\n",
    "        savepath_train_new = \"./RecomData/new/\" + dataset + \"/train\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        checkHolderExist(savepath_train_old)\n",
    "        checkHolderExist(savepath_train_new)\n",
    "\n",
    "\n",
    "\n",
    "        # 划分旧数据和新数据\n",
    "\n",
    "\n",
    "        data_train_path = dataset_path + \"/train/\" + dataset + \".csv\"\n",
    "\n",
    "\n",
    "\n",
    "        data_train = pd.read_csv(data_train_path, header=None).to_numpy()\n",
    "\n",
    "\n",
    "        data_train[np.isnan(data_train)] = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        data_train = minMaxNormalization(data_train)\n",
    "\n",
    "\n",
    "        np.save(savepath_train_old + \"/\" + dataset + \".npy\", data_train)\n",
    "        np.save(savepath_train_new + \"/\" + dataset + \".npy\", data_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    elif step == 2:\n",
    "        data_test_path = dataset_path + \"/test/\" + dataset + \".csv\"\n",
    "        data_test = pd.read_csv(data_test_path, header=None).to_numpy()\n",
    "        data_test[np.isnan(data_test)] = 0\n",
    "\n",
    "        savepath_test_old = \"./RecomData/old/\" + dataset + \"/test\"\n",
    "        savepath_test_new = \"./RecomData/new/\" + dataset + \"/test\"\n",
    "\n",
    "        checkHolderExist(savepath_test_new)\n",
    "        checkHolderExist(savepath_test_old)\n",
    "\n",
    "        split_index = dataset_split_config[dataset]\n",
    "\n",
    "        old_data_test = data_test[:split_index, :]\n",
    "        new_data_test = data_test[split_index:, :]\n",
    "\n",
    "        old_data_test = minMaxNormalization(old_data_test)\n",
    "        new_data_test = minMaxNormalization(new_data_test)\n",
    "\n",
    "        np.save(savepath_test_old + \"/\" + dataset + \".npy\", old_data_test)\n",
    "        np.save(savepath_test_new + \"/\" + dataset + \".npy\", new_data_test)\n",
    "\n",
    "\n",
    "    elif step == 3:\n",
    "        savepath_label_old = \"./RecomData/old/\" + dataset + \"/label\"\n",
    "        savepath_label_new = \"./RecomData/new/\" + dataset + \"/label\"\n",
    "\n",
    "\n",
    "        checkHolderExist(savepath_label_old)\n",
    "        checkHolderExist(savepath_label_new)\n",
    "        data_label_path = dataset_path + \"/label/\" + dataset + \".csv\"\n",
    "        label = pd.read_csv(data_label_path, header=None).to_numpy().squeeze()\n",
    "        split_index = dataset_split_config[dataset]\n",
    "        old_label = label[:split_index]\n",
    "        new_label = label[split_index:]\n",
    "\n",
    "        np.save(savepath_label_old + \"/\" + dataset + \".npy\", old_label)\n",
    "        np.save(savepath_label_new + \"/\" + dataset + \".npy\", new_label)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def datasetProcess():\n",
    "    dataset_pair = [ (\"UCR\", False),  (\"SMD\", False), (\"SMAP\", False), (\"SKAB\", True),\n",
    "                   (\"PMS\", True), (\"MSL\", False), (\"DMDS\", True)]\n",
    "\n",
    "    config = getConfigs()\n",
    "\n",
    "    dataset_split_config = getDatasetSplitConfig()\n",
    "\n",
    "    window_size = config[\"window_size\"]\n",
    "\n",
    "    for dataset, onlyone in dataset_pair:\n",
    "        print(\"dataset:\",dataset)\n",
    "        dataset_path = \"./Data/\" + dataset\n",
    "\n",
    "        savepath_train_old = \"./RecomData/old/\" + dataset + \"/train\"\n",
    "        savepath_train_new = \"./RecomData/new/\" + dataset + \"/train\"\n",
    "\n",
    "\n",
    "        savepath_test_old = \"./RecomData/old/\" + dataset + \"/test\"\n",
    "        savepath_label_old = \"./RecomData/old/\" + dataset + \"/label\"\n",
    "\n",
    "        savepath_test_new = \"./RecomData/new/\" + dataset + \"/test\"\n",
    "        savepath_label_new = \"./RecomData/new/\" + dataset + \"/label\"\n",
    "\n",
    "\n",
    "\n",
    "        checkHolderExist(savepath_train_old)\n",
    "        checkHolderExist(savepath_train_new)\n",
    "        checkHolderExist(savepath_test_old)\n",
    "        checkHolderExist(savepath_label_old)\n",
    "        checkHolderExist(savepath_test_new)\n",
    "        checkHolderExist(savepath_label_new)\n",
    "\n",
    "        #划分旧数据和新数据\n",
    "\n",
    "        if onlyone:\n",
    "            data_train_path = dataset_path + \"/train/\" + dataset + \".csv\"\n",
    "            data_test_path = dataset_path + \"/test/\" + dataset + \".csv\"\n",
    "            data_label_path = dataset_path + \"/label/\" + dataset + \".csv\"\n",
    "\n",
    "\n",
    "\n",
    "            data_train = pd.read_csv(data_train_path, header=None).to_numpy()\n",
    "            data_test = pd.read_csv(data_test_path, header=None).to_numpy()\n",
    "\n",
    "            data_train[np.isnan(data_train)] = 0\n",
    "            data_test[np.isnan(data_test)] = 0\n",
    "\n",
    "\n",
    "            label = pd.read_csv(data_label_path, header=None).to_numpy().squeeze()\n",
    "\n",
    "\n",
    "            split_index = dataset_split_config[dataset]\n",
    "\n",
    "            old_data_test = data_test[:split_index,:]\n",
    "            new_data_test = data_test[split_index:, :]\n",
    "\n",
    "            old_label = label[:split_index]\n",
    "            new_label = label[split_index:]\n",
    "\n",
    "\n",
    "            data_train = minMaxNormalization(data_train)\n",
    "            old_data_test = minMaxNormalization(old_data_test)\n",
    "            new_data_test = minMaxNormalization(new_data_test)\n",
    "\n",
    "\n",
    "            np.save(savepath_train_old + \"/\" + dataset + \".npy\", data_train)\n",
    "            np.save(savepath_train_new + \"/\" + dataset + \".npy\", data_train)\n",
    "\n",
    "\n",
    "            np.save(savepath_test_old + \"/\" + dataset + \".npy\",  old_data_test)\n",
    "            np.save(savepath_test_new + \"/\" + dataset + \".npy\",  new_data_test)\n",
    "\n",
    "            np.save(savepath_label_old + \"/\" + dataset + \".npy\",  old_label)\n",
    "            np.save(savepath_label_new + \"/\" + dataset + \".npy\", new_label)\n",
    "\n",
    "            del data_train\n",
    "            del old_data_test\n",
    "            del new_data_test\n",
    "            del old_label\n",
    "            del new_label\n",
    "\n",
    "        else:\n",
    "\n",
    "            data_train_path = dataset_path + \"/train/\"\n",
    "            data_test_path = dataset_path + \"/test/\"\n",
    "            data_label_path = dataset_path + \"/label/\"\n",
    "\n",
    "\n",
    "\n",
    "            data_files = os.listdir(data_train_path)\n",
    "\n",
    "\n",
    "            #随机划分新旧数据\n",
    "            files_new, files_old = splitFiles(data_files)\n",
    "            for file in files_new:\n",
    "                try:\n",
    "                    data_train = pd.read_csv(os.path.join(data_train_path, file), header=None).to_numpy()\n",
    "                    data_test = pd.read_csv(os.path.join(data_test_path, file), header=None).to_numpy()\n",
    "\n",
    "                    data_train[np.isnan(data_train)] = 0\n",
    "                    data_test[np.isnan(data_test)] = 0\n",
    "\n",
    "\n",
    "                    label = pd.read_csv(os.path.join(data_label_path, file), header=None).to_numpy().squeeze()\n",
    "\n",
    "                    data_train = minMaxNormalization(data_train)\n",
    "                    data_test = minMaxNormalization(data_test)\n",
    "\n",
    "\n",
    "\n",
    "                    filename = file.split(\".\")[0]\n",
    "                    np.save(savepath_train_new + \"/\" + filename + \".npy\", data_train)\n",
    "                    np.save(savepath_test_new + \"/\" + filename + \".npy\", data_test)\n",
    "                    np.save(savepath_label_new + \"/\" + filename + \".npy\", label)\n",
    "                except Exception as e:\n",
    "                    # 打印错误信息并跳过该文件\n",
    "                    print(f\"Error occurred while processing file {file}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            for file in files_old:\n",
    "                try:\n",
    "                    data_train = pd.read_csv(os.path.join(data_train_path, file), header=None).to_numpy()\n",
    "                    data_test = pd.read_csv(os.path.join(data_test_path, file), header=None).to_numpy()\n",
    "\n",
    "                    data_train[np.isnan(data_train)] = 0\n",
    "                    data_test[np.isnan(data_test)] = 0\n",
    "\n",
    "\n",
    "                    label = pd.read_csv(os.path.join(data_label_path, file), header=None).to_numpy().squeeze()\n",
    "\n",
    "                    data_train = minMaxNormalization(data_train)\n",
    "                    data_test = minMaxNormalization(data_test)\n",
    "\n",
    "\n",
    "                    filename = file.split(\".\")[0]\n",
    "                    np.save(savepath_train_old + \"/\" + filename + \".npy\", data_train)\n",
    "                    np.save(savepath_test_old + \"/\" + filename + \".npy\", data_test)\n",
    "                    np.save(savepath_label_old + \"/\" + filename + \".npy\", label)\n",
    "                except Exception as e:\n",
    "                    # 打印错误信息并跳过该文件\n",
    "                    print(f\"Error occurred while processing file {file}: {e}\")\n",
    "                    continue\n",
    "\n",
    "\n",
    "        #分割出新旧数据后，转变数据为滑动窗口\n",
    "        mode = \"old\"\n",
    "        recom_dataset_path =  \"./RecomData/\" + mode +\"/\" + dataset\n",
    "        data_files = os.listdir(recom_dataset_path + \"/train\")\n",
    "        for file in data_files:\n",
    "            writeWindowDataset(base_path=recom_dataset_path,filename=file,window_size=window_size)\n",
    "\n",
    "\n",
    "        mode = \"new\"\n",
    "        recom_dataset_path = \"./RecomData/\" + mode + \"/\" + dataset\n",
    "        data_files = os.listdir(recom_dataset_path + \"/train\")\n",
    "        for file in data_files:\n",
    "            writeWindowDataset(base_path=recom_dataset_path, filename=file, window_size=window_size)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e82fad7-5dc8-45d6-9e0a-bfbfa735dad1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def writeWindowDataset(base_path,filename,window_size):\n",
    "    '''\n",
    "    针对单个地址转化窗口保存，window_size由config指定\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "    data_train = np.load(base_path+\"/train/\"+filename)\n",
    "    data_test = np.load(base_path+\"/test/\"+filename)\n",
    "    label = np.load(base_path+\"/label/\"+filename)\n",
    "\n",
    "\n",
    "    train_window = convertToSlidingWindow(data_train, window_size=window_size)\n",
    "    test_window = convertToSlidingWindow(data_test, window_size=window_size)\n",
    "    label = label[window_size - 1:]\n",
    "\n",
    "    print(\"test_window shape:\",test_window.shape)\n",
    "    print(\"label shape:\",label.shape)\n",
    "\n",
    "    savepath_train = base_path + \"/window/train/\"\n",
    "    savepath_test = base_path + \"/window/test/\"\n",
    "    savepath_label = base_path + \"/window/label/\"\n",
    "    checkHolderExist(savepath_train)\n",
    "    checkHolderExist(savepath_test)\n",
    "    checkHolderExist(savepath_label)\n",
    "\n",
    "    np.save(savepath_train + \"/\" + filename , train_window)\n",
    "    np.save(savepath_test + \"/\" + filename , test_window)\n",
    "    np.save(savepath_label + \"/\" + filename , label)\n",
    "\n",
    "\n",
    "def evalOneDatasetFile(dataset_name,filename,mode = \"old\"):\n",
    "    config = getConfigs()\n",
    "    #model_list = [\"LSTMVAE\",\"LSTMAE\",\"NASALSTM\",\"DAGMM\",\"TRANSFORMER\",\"TCNAE\",\"UAE\",\"TRANAD\",\"OmniAnomaly\",\"PCAAD\",\"IForestAD\"]\n",
    "    model_list = [\"LSTMV2\"]\n",
    "    # model_list = [\"LSTMVAE\",\"PCAAD\"]\n",
    "    base_path = os.path.dirname(os.path.abspath(__file__))\n",
    "    #get data\n",
    "    window_size = config[\"window_size\"]\n",
    "    data_train,data_test,label = readData(dataset_path = base_path + \"/RecomData/\" + mode + \"/\" + dataset_name ,filename = filename,file_type = \"npy\")\n",
    "    label = label[window_size - 1:]\n",
    "    print(\"data_train shape:\",data_train.shape)\n",
    "    print(\"data_test shape:\", data_test.shape)\n",
    "    print(\"label shape:\", label.shape)\n",
    "    input_dim = data_train.shape[-1]\n",
    "\n",
    "    config[\"device\"] = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    config[\"base_path\"] = base_path\n",
    "    config[\"input_size\"] = input_dim\n",
    "\n",
    "    for method in model_list:\n",
    "        config[\"model_name\"] = method\n",
    "\n",
    "        if method in [\"TRANSFORMER\",\"TRANAD\"]:\n",
    "            config[\"epoch\"] = 5\n",
    "        else:\n",
    "            config[\"epoch\"] = 2\n",
    "\n",
    "        print(\"training method:\",method)\n",
    "\n",
    "        model = getModel(config)\n",
    "\n",
    "        config[\"model_param_num\"] = count_parameters(model)\n",
    "        config[\"identifier\"] = dataset_name+\"-\"+method\n",
    "        config[\"train_start_time\"] = time.time()\n",
    "        # train model\n",
    "        model.fit(train_data = data_train,write_log=True)\n",
    "        config[\"train_end_time\"] = time.time()\n",
    "\n",
    "        print(\"finish training method:\",method,\" cost time:\",config[\"train_end_time\"] - config[\"train_start_time\"])\n",
    "\n",
    "        config[\"test_start_time\"] = time.time()\n",
    "        anomaly_scores = model.test(data_test)\n",
    "        config[\"test_end_time\"] = time.time()\n",
    "        ori_predict_labels, ori_f1, ori_threshold = model.getBestPredict(anomaly_score=anomaly_scores, n_thresholds=25,\n",
    "                                                             ground_truth_label=label,protocol=\"\")\n",
    "\n",
    "\n",
    "        apa_predict_labels, apa_f1, apa_threshold = model.getBestPredict(anomaly_score=anomaly_scores, n_thresholds=25,\n",
    "                                                                         ground_truth_label=label,\n",
    "                                                                         protocol=\"apa\")\n",
    "\n",
    "        pa_predict_labels, pa_f1, pa_threshold = model.getBestPredict(anomaly_score=anomaly_scores, n_thresholds=25,\n",
    "                                                                      ground_truth_label=label,\n",
    "                                                                      protocol=\"pa\")\n",
    "\n",
    "        (tp, fp, tn, fn) = countResult(predict_labels=ori_predict_labels, ground_truth=label)\n",
    "        config[\"ori_tp\"] = float(tp)\n",
    "        config[\"ori_fp\"] = float(fp)\n",
    "        config[\"ori_tn\"] = float(tn)\n",
    "        config[\"ori_fn\"] = float(fn)\n",
    "\n",
    "        print(\"finish evaluating method:\", method)\n",
    "        # visualization\n",
    "        plot_yaxis = []\n",
    "        plot_yaxis.append(anomaly_scores)\n",
    "        plot_yaxis.append(ori_predict_labels)\n",
    "        plot_yaxis.append(apa_predict_labels)\n",
    "        plot_yaxis.append(pa_predict_labels)\n",
    "\n",
    "        plot_path = base_path + \"/Plots/recommondation/\" + mode + \"/\" + dataset_name +\"/\" + filename\n",
    "\n",
    "        checkHolderExist(plot_path)\n",
    "\n",
    "        plotAllResult(x_axis=np.arange(len(anomaly_scores)), y_axises=plot_yaxis, title=config[\"model_name\"],\n",
    "                      save_path=plot_path + \"/\" + method + \".pdf\",\n",
    "                      segments=findSegment(label),\n",
    "                      threshold=None)\n",
    "\n",
    "        # config[\"anomaly_score\"] = anomaly_scores.tolist()\n",
    "        score_save_path = base_path + \"/RecomData/scores/\" + mode + \"/\"  + dataset_name + \"/\" + filename\n",
    "\n",
    "        checkHolderExist(score_save_path)\n",
    "        np.save(score_save_path + \"/\"  + method +\".npy\",anomaly_scores)\n",
    "        # config[\"ori_predict_labels\"] = ori_predict_labels.tolist()\n",
    "        # config[\"pa_predict_labels\"] = pa_predict_labels.tolist()\n",
    "        # config[\"apa_predict_labels\"] = apa_predict_labels.tolist()\n",
    "\n",
    "        config[\"ori_f1\"] = ori_f1\n",
    "        config[\"apa_f1\"] = apa_f1\n",
    "        config[\"pa_f1\"] = pa_f1\n",
    "\n",
    "        config[\"ori_threshold\"] = ori_threshold\n",
    "        config[\"apa_threshold\"] = apa_threshold\n",
    "        config[\"pa_threshold\"] = pa_threshold\n",
    "        config[\"device\"] = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        wirteLog(base_path + \"/Logs/recommondation/\" + mode + \"/\"  + dataset_name + \"/\" + filename ,method,config)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"finish training model. start to test model.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e49e50c6-f564-497e-ade7-ed743b614eee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sampleFromWindowData(data: np.ndarray,sample_num:int,indices:np.ndarray = np.array([])):\n",
    "    length = len(data)\n",
    "\n",
    "    results = []\n",
    "    if len(indices) == 0 :\n",
    "        # 计算均匀间隔\n",
    "        interval = length // sample_num\n",
    "        if interval < sample_num :\n",
    "            indices = np.random.choice(length, sample_num, replace=False)\n",
    "        else:\n",
    "            indexes = []\n",
    "            for i in range(sample_num):\n",
    "                idx = random.randint(i*interval,(i+1)*interval-1)\n",
    "                indexes.append(idx)\n",
    "            indices = indexes\n",
    "\n",
    "    for sample_index in indices:\n",
    "        results.append(data[sample_index])\n",
    "    \n",
    "    return results,indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b8f825-dc10-48df-a64e-2739d2175236",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d96572a-81cc-4a0d-85a5-f766860eacb2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getEvaluationResult(mode = \"old\",dataset_list = [],method_list = []):\n",
    "    path = \"./Logs/recommondation/\" + mode +\"/\"\n",
    "    result = {}\n",
    "    for dataset,isonly in dataset_list:\n",
    "\n",
    "        result[dataset] = {}\n",
    "\n",
    "        files_path = path + dataset\n",
    "\n",
    "        file_names = os.listdir(files_path)\n",
    "\n",
    "        for file_name in file_names:\n",
    "            file_name = file_name.split(\".\")[0]\n",
    "\n",
    "            result[dataset][file_name] = {}\n",
    "\n",
    "            for method in method_list:\n",
    "                result[dataset][file_name][method] = {}\n",
    "                eval_path = files_path + \"/\" + file_name + \"/\" + method + \".json\"\n",
    "                with open(eval_path, \"r\") as file:\n",
    "                    data_dict = json.load(file)\n",
    "\n",
    "                result[dataset][file_name][method][\"ori_f1\"] = data_dict[\"ori_f1\"]\n",
    "                result[dataset][file_name][method][\"pa_f1\"] = data_dict[\"pa_f1\"]\n",
    "                result[dataset][file_name][method][\"ori_f1\"] = data_dict[\"ori_f1\"]\n",
    "\n",
    "                result[dataset][file_name][method][\"pa_threshold\"] = data_dict[\"pa_threshold\"]\n",
    "                result[dataset][file_name][method][\"apa_threshold\"] = data_dict[\"apa_threshold\"]\n",
    "                result[dataset][file_name][method][\"ori_threshold\"] = data_dict[\"ori_threshold\"]\n",
    "\n",
    "    return result\n",
    "\n",
    "def countSame(sample,all_sample):\n",
    "    count = np.sum(np.all(sample == all_sample, axis=(1, 2)))\n",
    "    return count\n",
    "\n",
    "def batchDiscretize(all_sample):\n",
    "    result = []\n",
    "    for item in all_sample:\n",
    "        result.append(discretize(item))\n",
    "    return result\n",
    "def discretize(data):\n",
    "    \"\"\"\n",
    "    将形状为[batch, window, channel]数值离散化\n",
    "    \"\"\"\n",
    "    # 创建一个存储离散化结果的新数组\n",
    "    data = np.floor(data * 10) / 10  # 先乘以10，再使用floor，然后再除以10\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f66ee50-b9a4-481e-8d22-fc1e4b8e4404",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getDatasetDetectability(origin_sample_list,new_sample_list,old_anomaly_scores,threshold,label_samples ,params):\n",
    "    total_dec = 0\n",
    "    for new_index, new_sample in enumerate(new_sample_list):\n",
    "        m_dec = getMatchScore(sample = new_sample,ori_sample_list = origin_sample_list,threshold = threshold,anomaly_score = old_anomaly_scores,label_samples = label_samples,params = params)\n",
    "        total_dec += m_dec\n",
    "    return total_dec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d495fa2-48a9-4bf7-bfeb-d46e4d34e2ee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# def getMatchScore(sample,ori_sample_list,threshold,anomaly_score,label_samples,params):\n",
    "#     m_dec = 0\n",
    "#     recall = params[\"recall\"]\n",
    "#     precision = params[\"precision\"]\n",
    "#     # ratio = params[\"anomaly_ratio\"]\n",
    "#     for index,ori_sample in enumerate(ori_sample_list):\n",
    "#         similarity = getSimilarity(sample, ori_sample)\n",
    "#         if similarity < threshold:\n",
    "#             m_dec +=  np.sum(  precision * np.multiply(label_samples[index],anomaly_score[index] ) +  recall * np.multiply((1 - label_samples[index]),(1-anomaly_score[index])) )\n",
    "\n",
    "#     return m_dec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3e7d186-fc57-468b-ba53-ced60006a275",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getMatchScore(sample,ori_sample_list,threshold,anomaly_score,label_samples,params):\n",
    "    m_dec = 0\n",
    "    recall = params[\"recall\"] + 1e-6\n",
    "    precision = params[\"precision\"] + 1e-6\n",
    "    f1 = params[\"f1\"] + 1e-6\n",
    "    ratio = params[\"anomaly_ratio\"]\n",
    "    for index,ori_sample in enumerate(ori_sample_list):\n",
    "        similarity = getSimilarity(sample, ori_sample)\n",
    "        if similarity < threshold:\n",
    "            m_dec +=  np.sum( (1/(1-max(f1,precision))) *  np.multiply(label_samples[index],anomaly_score[index] ) + ratio * recall * np.multiply((1 - label_samples[index]),(1-anomaly_score[index])) )\n",
    "\n",
    "    return m_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "187e2334-137d-41af-b6e3-d27fc94d9363",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getDatasetSimilarity(origin_sample_list,new_sample_list,old_anomaly_scores,old_label_samples,threshold = 0.5,params = {}):\n",
    "\n",
    "    '''\n",
    "    计算新数据列表和旧数据列表的相似性，返回列表\n",
    "    :param origin_sample_list: 需要比较的旧数据的样本列表,即窗口列表\n",
    "    :param new_sample_list: 需要比较的新数据的样本列表,即窗口列表\n",
    "    :return:返回列表格式，每个新数据样本对应的相似性最大的旧数据样本的Index以及相似性数值。 [(max_similarity_index,max_similarity)]\n",
    "    '''\n",
    "    origin_sample_list = batchDiscretize(origin_sample_list)\n",
    "    new_sample_list = batchDiscretize(new_sample_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    new_counts_map = getDistinctAndNum(new_sample_list)\n",
    "\n",
    "    ori_len = len(origin_sample_list)\n",
    "    new_len = len(new_sample_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    new_sample_list = unique(new_sample_list)\n",
    "\n",
    "\n",
    "    p = np.zeros(len(new_sample_list))\n",
    "    for index,item in enumerate(new_sample_list):\n",
    "        key = getMatrixKey(item)\n",
    "        p[index] = new_counts_map[key]\n",
    "\n",
    "    p = Softmax(p + 1e-7)\n",
    "\n",
    "    q = np.zeros_like(p)\n",
    "\n",
    "    total_c = 0\n",
    "    c_list = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for new_index,new_sample in enumerate(new_sample_list):\n",
    "\n",
    "        counts,similar_sample_index_list = calculateSimilarityCounts(new_sample, origin_sample_list, threshold)\n",
    "        q[new_index] = counts\n",
    "        total_c += counts\n",
    "        c_list = list(set(c_list + similar_sample_index_list))\n",
    "\n",
    "    len_cd1 =  len(c_list)\n",
    "\n",
    "    q = q / (ori_len - len_cd1 + total_c )\n",
    "    q = Softmax(q + 1e-8)\n",
    "    dataset_similarity = 1 / (p * np.log(p/q) +1e-8).sum()\n",
    "\n",
    "    \n",
    "\n",
    "    m_dec_total = getDatasetDetectability(origin_sample_list, new_sample_list, old_anomaly_scores, threshold,old_label_samples,params)\n",
    "    #print(\"dataset_similarity = \", dataset_similarity,\"m_dec_total = \", m_dec_total )\n",
    "    total_similarity = dataset_similarity * m_dec_total\n",
    "\n",
    "    return total_similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58385377-7811-411a-9911-1b4e5e30e9b5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getEvalCount(mode=\"old\", dataset=\"\", method_list=[]):\n",
    "    path = \"./Logs/recommondation/\" + mode + \"/\"\n",
    "    result = {}\n",
    "\n",
    "    result[dataset] = {}\n",
    "\n",
    "    files_path = path + dataset\n",
    "\n",
    "    file_names = os.listdir(files_path)\n",
    "\n",
    "    for file_name in file_names:\n",
    "        file_name = file_name.split(\".\")[0]\n",
    "\n",
    "        result[dataset][file_name] = {}\n",
    "\n",
    "        for method in method_list:\n",
    "            result[dataset][file_name][method] = {}\n",
    "            eval_path = files_path + \"/\" + file_name + \"/\" + method + \".json\"\n",
    "            with open(eval_path, \"r\") as file:\n",
    "                data_dict = json.load(file)\n",
    "\n",
    "            result[dataset][file_name][method][\"tp\"] = data_dict[\"ori_tp\"]\n",
    "            result[dataset][file_name][method][\"fp\"] = data_dict[\"ori_fp\"]\n",
    "            result[dataset][file_name][method][\"tn\"] = data_dict[\"ori_tn\"]\n",
    "            result[dataset][file_name][method][\"fn\"] = data_dict[\"ori_fn\"]\n",
    "            if (data_dict[\"ori_tp\"] + data_dict[\"ori_fp\"]) <= 0 :\n",
    "                result[dataset][file_name][method][\"precision\"] = 0\n",
    "            else:\n",
    "                result[dataset][file_name][method][\"precision\"] = data_dict[\"ori_tp\"] / (data_dict[\"ori_tp\"] + data_dict[\"ori_fp\"])\n",
    "\n",
    "            if (data_dict[\"ori_tp\"] + data_dict[\"ori_fn\"]) <= 0:\n",
    "                result[dataset][file_name][method][\"recall\"] = 0\n",
    "            else:\n",
    "                result[dataset][file_name][method][\"recall\"] = data_dict[\"ori_tp\"] / (data_dict[\"ori_tp\"] + data_dict[\"ori_fn\"])\n",
    "                \n",
    "\n",
    "            result[dataset][file_name][method][\"f1\"] = data_dict[\"ori_f1\"]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba15b0ec-dcd1-4fbc-86d8-431985dd627d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculateSimilarityCounts(sample,ori_sample_list,threshold):\n",
    "    counts = 0\n",
    "    similar_sample_index_list = []\n",
    "\n",
    "    for index,ori_sample in enumerate(ori_sample_list):\n",
    "        if ori_sample.shape != sample.shape:\n",
    "            print(\"shape dont match!:\",ori_sample.shape,sample.shape)\n",
    "        ori_sample = ori_sample.flatten()\n",
    "        \n",
    "        similarity = getSimilarity(sample.flatten() ,ori_sample)\n",
    "   \n",
    "        if similarity < threshold:\n",
    "            # print(\"similarity:\",similarity,\" threshold:\",threshold)\n",
    "            counts += 1\n",
    "            similar_sample_index_list.append(index)\n",
    "\n",
    "    return counts,similar_sample_index_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1e07bd8-99fc-4a37-bd50-4ea2ed5a1e91",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getSimilarity(origin_sample,new_sample):\n",
    "    '''\n",
    "    具体计算相似性的函数，相似性的计算逻辑更改时修改此处。如新添加了相似性计算函数\n",
    "    :param origin_sample:\n",
    "    :param new_sample:\n",
    "    :return:\n",
    "    '''\n",
    "    prob_origin_sample = Softmax(origin_sample + 1e-7)\n",
    "    prob_new_sample = Softmax(new_sample + 1e-7)\n",
    "\n",
    "    kl = KLDivergence(prob_origin_sample,prob_new_sample)\n",
    "\n",
    "    # js = JSDivergence(prob_origin_sample,prob_new_sample)\n",
    "\n",
    "    return kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10db5b50-50a0-4eed-b7ae-e9eb97edc69e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sampleAndMatch(dataset,old_filename,new_filename,method_list,sample_num = 100,threshold = 0.5):\n",
    "    config = getConfigs()\n",
    "    # print(\"sample - dataset:\", dataset)\n",
    "    dataset_old_path = \"./RecomData/old/\" + dataset + \"/window/test/\" + old_filename + \".npy\"\n",
    "    dataset_new_path = \"./RecomData/new/\" + dataset + \"/window/test/\" + new_filename + \".npy\"\n",
    "    dataset_old_label_path = \"./RecomData/old/\" + dataset + \"/window/label/\" + old_filename + \".npy\"\n",
    "\n",
    "\n",
    "    old_window_data = np.load(dataset_old_path)\n",
    "    new_window_data = np.load(dataset_new_path)\n",
    "\n",
    "    old_data_length = int(len(old_window_data)*0.95)\n",
    "\n",
    "\n",
    "    old_label_data = np.load(dataset_old_label_path)\n",
    "\n",
    "\n",
    "    old_window_data = old_window_data[-old_data_length:]\n",
    "    new_window_data = new_window_data[-old_data_length:]\n",
    "    old_label_data = old_label_data[-old_data_length:]\n",
    "    \n",
    "    old_window_samples,old_indices = sampleFromWindowData(old_window_data,sample_num)\n",
    "    new_window_samples,new_indices = sampleFromWindowData(new_window_data,sample_num)\n",
    "    old_label_samples,new_indices = sampleFromWindowData(old_label_data,sample_num)\n",
    "\n",
    "\n",
    "    # print(\"new dataset . len: \", len(new_window_samples),\" shape:\",old_window_samples[0].shape)\n",
    "\n",
    "    # new_window_samples = unique(new_window_samples)\n",
    "\n",
    "    method_recommond_score = []\n",
    "    method_score_map = {}\n",
    "    all_params = getEvalCount(mode=\"old\", dataset=dataset, method_list=method_list)\n",
    "    anomaly_ratio = np.sum(old_label_data)/(len(old_label_data) * config[\"window_size\"])\n",
    "    for method in method_list:\n",
    "\n",
    "        score_path = \"./RecomData/scores/old/\" + dataset + \"/\" + old_filename + \"/\" + method + \".npy\"\n",
    "        anomaly_scores = np.load(score_path)\n",
    "        anomaly_scores = anomaly_scores[:, np.newaxis]\n",
    "\n",
    "        anomaly_scores = convertToWindow(anomaly_scores,config[\"window_size\"]).squeeze()\n",
    "   \n",
    "        anomaly_scores = anomaly_scores[-old_data_length:]\n",
    "        anomaly_scores_samples,_ = sampleFromWindowData(anomaly_scores,sample_num,indices=old_indices)\n",
    "        #old_label_samples,_ = sampleFromWindowData(old_label_data,sample_num,indices=old_indices)\n",
    "\n",
    "        params = all_params[dataset][old_filename][method]\n",
    "        params[\"anomaly_ratio\"] = anomaly_ratio\n",
    "        total_dataset_recommond_score = getDatasetSimilarity(old_window_samples,new_window_samples,old_anomaly_scores=anomaly_scores_samples,old_label_samples = old_label_samples,threshold = threshold,params=params)\n",
    "        # print(\"method:\",method,\" score:\",total_dataset_recommond_score)\n",
    "        method_score_map[method] = total_dataset_recommond_score\n",
    "        method_recommond_score.append(total_dataset_recommond_score)\n",
    "\n",
    "\n",
    "    max_score_index = np.array(method_recommond_score).argmax(axis=0)\n",
    "    max_score = np.array(method_recommond_score).max(axis=0)\n",
    "    method_score_map = dict(sorted(method_score_map.items(), key=lambda x: x[1], reverse=True))\n",
    "    recommon_method = method_list[max_score_index]\n",
    "    return recommon_method,max_score,method_score_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5adfd57-7f1f-4188-8d87-fc12adb60f6b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def bordaAggregation(rank_list,method_list):\n",
    "\n",
    "    \n",
    "    file_list = []\n",
    "    for item in rank_list:\n",
    "        sorted_res = sorted(item.items(), key=lambda x: x[1], reverse=True)\n",
    "        mapt = {}\n",
    "        index = 1\n",
    "\n",
    "        for item in sorted_res:\n",
    "        \n",
    "            mapt[item[0]] = index\n",
    "            index += 1\n",
    "\n",
    "        file_list.append(mapt)\n",
    "\n",
    "    \n",
    "    rank_map = {\n",
    "    }\n",
    "\n",
    "    for method in method_list:\n",
    "        if rank_map.get(method) == None:\n",
    "            rank_map[method] = []\n",
    "\n",
    "        for rank_file in file_list:\n",
    "            rank_map[method].append(rank_file[method])\n",
    "\n",
    "\n",
    "    num_competitors = len(rank_map.keys())\n",
    "\n",
    "    scores = {method: 0 for method in method_list}\n",
    "\n",
    "    for competitor, ranks in rank_map.items():\n",
    "        for rank in ranks:\n",
    "            scores[competitor] += (num_competitors - rank)\n",
    "\n",
    "    sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8220e1ca-d472-4423-b373-29410272c93b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def recommendAll(dataset_list=[], method_list = [\"LSTMVAE\",\"LSTMAE\",\"NASALSTM\",\"DAGMM\",\"TRANSFORMER\",\"TCNAE\",\"UAE\",\"TRANAD\",\"OmniAnomaly\",\"PCAAD\",\"IForestAD\"]):\n",
    "\n",
    "\n",
    "    file_recommond_method_list = []\n",
    "\n",
    "    dataset_recommond_rank = {}\n",
    "\n",
    "    for dataset,isonly in dataset_list:\n",
    "        print(\"recommending dataset:\",dataset)\n",
    "        if isonly:\n",
    "            old_filename = dataset\n",
    "            new_filename = dataset\n",
    "            recommond_method,max_score,rank_map = sampleAndMatch(dataset,old_filename=old_filename,new_filename=new_filename,method_list=method_list,sample_num=100,threshold = 0.5)\n",
    "            file_recommond_method_list.append((dataset, dataset , recommond_method))\n",
    "            dataset_recommond_rank[dataset] = rank_map\n",
    "            print(\"recommond method:\", recommond_method)\n",
    "            print(\"method rank:\",rank_map)\n",
    "        else:\n",
    "\n",
    "\n",
    "            old_data_path = \"./RecomData/old/\" + dataset + \"/window/test/\"\n",
    "            new_data_path = \"./RecomData/new/\" + dataset + \"/window/test/\"\n",
    "\n",
    "            old_data_files = os.listdir(old_data_path)\n",
    "            new_data_files = os.listdir(new_data_path)\n",
    "\n",
    "            file_recommond_rank_list = []\n",
    "            for new_filename in new_data_files:\n",
    "                file_recommond_rank_map = {}\n",
    "                print(\"new_filename:\",new_filename)\n",
    "                total_rec_method = \"\"\n",
    "                total_max_score = 0\n",
    "                for old_filename in old_data_files:\n",
    "                    # print(\"old_filename:\", old_filename)\n",
    "                    recommond_method, max_score,rank_map = sampleAndMatch(dataset, old_filename=old_filename.split(\".\")[0],\n",
    "                                                                new_filename=new_filename.split(\".\")[0], method_list=method_list,\n",
    "                                                                sample_num=100,threshold = 0.5)\n",
    "\n",
    "                    for (method,score) in rank_map.items():\n",
    "                        if file_recommond_rank_map.get(method) == None:\n",
    "                            file_recommond_rank_map[method] = score\n",
    "                        else:\n",
    "                            file_recommond_rank_map[method] = max(file_recommond_rank_map[method],score)\n",
    "\n",
    "                    # print(\"recommond method:\",recommond_method)\n",
    "                    if max_score > total_max_score:\n",
    "                        total_max_score = max_score\n",
    "                        total_rec_method = recommond_method\n",
    "\n",
    "                file_recommond_rank_list.append(file_recommond_rank_map)\n",
    "                file_recommond_method_list.append((dataset,new_filename,total_rec_method))\n",
    "\n",
    "            aggratated_rank = bordaAggregation(file_recommond_rank_list,method_list)\n",
    "            dataset_recommond_rank[dataset] = aggratated_rank\n",
    "    print(\"final result:\")\n",
    "    print(file_recommond_method_list)\n",
    "    print(\"dataset_recommond_rank：\\n\",dataset_recommond_rank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702667de-d6b8-4ed0-99e2-825fdf8f1552",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50fc0186-027c-4743-b4af-2e91eea532c8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compareRuntime(window_size,sample_num,threshold):\n",
    "    dataset_list = [(\"SWAT\", True), (\"SKAB\", True),\n",
    "                    (\"PMS\", True),  (\"DMDS\", True)]\n",
    "    method_list = [\"LSTMVAE\", \"LSTMAE\", \"NASALSTM\", \"DAGMM\", \"TRANSFORMER\", \"TCNAE\", \"UAE\", \"TRANAD\", \"OmniAnomaly\",\n",
    "                   \"PCAAD\", \"IForestAD\"]\n",
    "\n",
    "\n",
    "    running_time_list = []\n",
    "\n",
    "    for dataset,isonly in dataset_list:\n",
    "        print(\"recommending dataset:\",dataset)\n",
    "\n",
    "        old_filename = dataset\n",
    "        new_filename = dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(\"sample - dataset:\", dataset)\n",
    "        dataset_old_path = \"./RecomData/old/\" + dataset + \"/test/\" + old_filename + \".npy\"\n",
    "        dataset_new_path = \"./RecomData/new/\" + dataset + \"/test/\" + new_filename + \".npy\"\n",
    "        dataset_old_label_path = \"./RecomData/old/\" + dataset + \"/label/\" + old_filename + \".npy\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        old_window_data = np.load(dataset_old_path)\n",
    "        new_window_data = np.load(dataset_new_path)\n",
    "\n",
    "        print(\"old data length:\", len(old_window_data))\n",
    "        print(\"new data length:\", len(new_window_data))\n",
    "\n",
    "        old_label_data = np.load(dataset_old_label_path)\n",
    "\n",
    "        all_params = getEvalCount(mode=\"old\", dataset=dataset, method_list=method_list)\n",
    "        anomaly_ratio = np.sum(old_label_data) / len(old_label_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        old_window_data = convertToSlidingWindow(old_window_data,window_size)\n",
    "        new_window_data = convertToSlidingWindow(new_window_data,window_size)\n",
    "        old_label_data = convertToSlidingWindow(old_label_data,window_size)\n",
    "\n",
    "\n",
    "\n",
    "        old_data_length = int(len(old_window_data) * 0.95)\n",
    "\n",
    "        old_window_data = old_window_data[-old_data_length:]\n",
    "        new_window_data = new_window_data[-old_data_length:]\n",
    "        old_label_data = old_label_data[-old_data_length:]\n",
    "\n",
    "        starttime =  time.time()\n",
    "        print(\"start sample. start time:\", starttime)\n",
    "\n",
    "        old_window_samples, old_indices = sampleFromWindowData(old_window_data, sample_num)\n",
    "        new_window_samples, new_indices = sampleFromWindowData(new_window_data, sample_num)\n",
    "        old_label_samples, new_indices = sampleFromWindowData(old_label_data, sample_num, old_indices)\n",
    "\n",
    "\n",
    "        method_recommond_score = []\n",
    "        method_score_map = {}\n",
    "\n",
    "\n",
    "        for method in method_list:\n",
    "            score_path = \"./RecomData/scores/old/\" + dataset + \"/\" + old_filename + \"/\" + method + \".npy\"\n",
    "            anomaly_scores = np.load(score_path)\n",
    "            anomaly_scores = anomaly_scores[:, np.newaxis]\n",
    "\n",
    "            anomaly_scores = convertToWindow(anomaly_scores, window_size).squeeze()[-old_data_length:]\n",
    "\n",
    "            anomaly_scores, new_indices = sampleFromWindowData(anomaly_scores, sample_num,old_indices)\n",
    "\n",
    "            params = all_params[dataset][old_filename][method]\n",
    "            params[\"anomaly_ratio\"] = anomaly_ratio\n",
    "            total_dataset_recommond_score = getDatasetSimilarity(old_window_samples, new_window_samples,\n",
    "                                                                 old_anomaly_scores=anomaly_scores,\n",
    "                                                                 old_label_samples=old_label_samples,\n",
    "                                                                 threshold=threshold, params=params)\n",
    "            # print(\"method:\", method, \" score:\", total_dataset_recommond_score)\n",
    "            method_score_map[method] = total_dataset_recommond_score\n",
    "            method_recommond_score.append(total_dataset_recommond_score)\n",
    "        \n",
    "\n",
    "\n",
    "        endtime =  time.time()\n",
    "        print(\"start sample. end time:\", endtime)\n",
    "        print(\"dataset:\",dataset,\" running time:\",endtime-starttime,\" window_size:\",window_size,\" sample_num:\",sample_num)\n",
    "        running_time_list.append(endtime-starttime)\n",
    "        max_score_index = np.array(method_recommond_score).argmax(axis=0)\n",
    "        max_score = np.array(method_recommond_score).max(axis=0)\n",
    "        method_score_map = dict(sorted(method_score_map.items(), key=lambda x: x[1], reverse=True))\n",
    "        recommon_method = method_list[max_score_index]\n",
    "        print(\"rank :\", method_score_map)\n",
    "\n",
    "    print(running_time_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03641bee-d58a-4b7d-b563-7265c2da9819",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommending dataset: SWAT\n",
      "sample - dataset: SWAT\n",
      "old data length: 155000\n",
      "new data length: 294918\n",
      "start sample. start time: 1719657976.1575925\n",
      "start sample. end time: 1719657984.74522\n",
      "dataset: SWAT  running time: 8.587627410888672  window_size: 10  sample_num: 100\n",
      "rank : {'DAGMM': 6130551267.078446, 'IForestAD': 3645521620.678625, 'TRANAD': 3146135839.906925, 'LSTMAE': 3019675099.327545, 'OmniAnomaly': 2776737554.3363147, 'NASALSTM': 2505363278.2724543, 'LSTMVAE': 2453550888.591881, 'TRANSFORMER': 2023477313.2056267, 'UAE': 84671888.59373264, 'PCAAD': 42572857.808493935, 'TCNAE': 2962774.7001567734}\n",
      "recommending dataset: SKAB\n",
      "sample - dataset: SKAB\n",
      "old data length: 26322\n",
      "new data length: 11137\n",
      "start sample. start time: 1719657984.789423\n",
      "start sample. end time: 1719657991.032423\n",
      "dataset: SKAB  running time: 6.243000030517578  window_size: 10  sample_num: 100\n",
      "rank : {'TCNAE': 35667811851.80256, 'PCAAD': 35571644469.48403, 'IForestAD': 32461934083.551968, 'NASALSTM': 32045133187.87235, 'TRANAD': 31460018822.25121, 'LSTMVAE': 30436091779.120617, 'OmniAnomaly': 29314873728.02122, 'LSTMAE': 27201225517.87537, 'DAGMM': 26875825072.901474, 'TRANSFORMER': 21811397531.439705, 'UAE': 1040971533.6442792}\n",
      "recommending dataset: PMS\n",
      "sample - dataset: PMS\n",
      "old data length: 53122\n",
      "new data length: 34719\n",
      "start sample. start time: 1719657991.1815755\n",
      "start sample. end time: 1719657998.2224054\n",
      "dataset: PMS  running time: 7.04082989692688  window_size: 10  sample_num: 100\n",
      "rank : {'TCNAE': 37078762947.73591, 'NASALSTM': 21007322548.943653, 'IForestAD': 20446735025.693695, 'LSTMVAE': 19229699918.570923, 'OmniAnomaly': 19081550625.13314, 'LSTMAE': 18814249720.915073, 'DAGMM': 18678017658.7906, 'TRANSFORMER': 18152438024.50792, 'TRANAD': 16507209970.894316, 'UAE': 1013334948.5367413, 'PCAAD': 462130442.0944801}\n",
      "recommending dataset: DMDS\n",
      "sample - dataset: DMDS\n",
      "old data length: 200000\n",
      "new data length: 59200\n",
      "start sample. start time: 1719657998.7794921\n",
      "start sample. end time: 1719658007.6141155\n",
      "dataset: DMDS  running time: 8.834623336791992  window_size: 10  sample_num: 100\n",
      "rank : {'OmniAnomaly': 833945753.9256349, 'LSTMAE': 701742256.5570486, 'LSTMVAE': 689049616.0773189, 'TRANAD': 642392934.4325812, 'PCAAD': 610408619.8907212, 'IForestAD': 471926359.9310578, 'NASALSTM': 457049458.7763451, 'TRANSFORMER': 316737256.3631879, 'UAE': 152333185.90167618, 'TCNAE': 1485663.7943402256, 'DAGMM': -696627043334542.6}\n",
      "[8.587627410888672, 6.243000030517578, 7.04082989692688, 8.834623336791992]\n"
     ]
    }
   ],
   "source": [
    "compareRuntime(10,100,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c511f1ac-c64d-4b75-a0ee-aa6db0873039",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommending dataset: SWAT\n",
      "sample - dataset: SWAT\n",
      "old data length: 155000\n",
      "new data length: 294918\n",
      "start sample. start time: 1719658010.3007371\n",
      "start sample. end time: 1719658020.7727683\n",
      "dataset: SWAT  running time: 10.472031116485596  window_size: 30  sample_num: 100\n",
      "rank : {'DAGMM': 184057.25103749358, 'NASALSTM': 148194.09731545785, 'TRANAD': 146659.5924101111, 'LSTMAE': 140630.83357479918, 'OmniAnomaly': 127802.9426395609, 'IForestAD': 122202.52208014381, 'TRANSFORMER': 116132.77411133044, 'LSTMVAE': 107435.0775905765, 'PCAAD': 3306.244002493162, 'UAE': 1914.6809595673292, 'TCNAE': 146.54593218431563}\n",
      "recommending dataset: SKAB\n",
      "sample - dataset: SKAB\n",
      "old data length: 26322\n",
      "new data length: 11137\n",
      "start sample. start time: 1719658020.8306487\n",
      "start sample. end time: 1719658028.0086691\n",
      "dataset: SKAB  running time: 7.178020477294922  window_size: 30  sample_num: 100\n",
      "rank : {'TCNAE': 107338386380.27792, 'PCAAD': 99457481073.23006, 'IForestAD': 97794494817.04028, 'TRANAD': 97153174144.69305, 'NASALSTM': 96989014589.9732, 'LSTMVAE': 94041363735.15613, 'OmniAnomaly': 90041071223.51082, 'LSTMAE': 84647979474.727, 'DAGMM': 75705266903.18869, 'TRANSFORMER': 66753458513.5806, 'UAE': 2511300401.209117}\n",
      "recommending dataset: PMS\n",
      "sample - dataset: PMS\n",
      "old data length: 53122\n",
      "new data length: 34719\n",
      "start sample. start time: 1719658028.3069735\n",
      "start sample. end time: 1719658036.393721\n",
      "dataset: PMS  running time: 8.086747646331787  window_size: 30  sample_num: 100\n",
      "rank : {'NASALSTM': 63015568432.87407, 'IForestAD': 58224614607.390495, 'DAGMM': 57712239593.436935, 'LSTMVAE': 55115578772.052536, 'OmniAnomaly': 54843654169.817505, 'LSTMAE': 53340638048.41624, 'TRANSFORMER': 52218053698.87542, 'TRANAD': 47879204093.69246, 'TCNAE': 5973425913.319369, 'UAE': 2923312383.310453, 'PCAAD': 1023198806.0291456}\n",
      "recommending dataset: DMDS\n",
      "sample - dataset: DMDS\n",
      "old data length: 200000\n",
      "new data length: 59200\n",
      "start sample. start time: 1719658037.490162\n",
      "start sample. end time: 1719658047.6834648\n",
      "dataset: DMDS  running time: 10.193302869796753  window_size: 30  sample_num: 100\n",
      "rank : {'IForestAD': 529116077.1528554, 'PCAAD': 500021743.0351172, 'TRANAD': 451812991.87605846, 'LSTMAE': 437669659.6180009, 'OmniAnomaly': 423765322.52203006, 'LSTMVAE': 417580073.1749732, 'TRANSFORMER': 310826238.8351343, 'UAE': 224524840.44703743, 'NASALSTM': 218871527.89954475, 'DAGMM': 92209205.96215174, 'TCNAE': 4502011.498000713}\n",
      "[10.472031116485596, 7.178020477294922, 8.086747646331787, 10.193302869796753]\n"
     ]
    }
   ],
   "source": [
    "compareRuntime(30,100,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42491489-4359-44fd-b205-4cc86dabeb3e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommending dataset: SWAT\n",
      "sample - dataset: SWAT\n",
      "old data length: 155000\n",
      "new data length: 294918\n",
      "start sample. start time: 1719658052.513463\n",
      "start sample. end time: 1719658066.3324385\n",
      "dataset: SWAT  running time: 13.818975448608398  window_size: 60  sample_num: 100\n",
      "rank : {'DAGMM': 19434120883.341087, 'TRANAD': 18908128086.169422, 'LSTMAE': 18636850865.105045, 'NASALSTM': 18400271754.795757, 'OmniAnomaly': 16515944062.22805, 'TRANSFORMER': 15455429295.29293, 'IForestAD': 15435178770.32758, 'LSTMVAE': 14492699861.03906, 'PCAAD': 2286746712.9351754, 'UAE': 392854504.079298, 'TCNAE': 18693411.396293372}\n",
      "recommending dataset: SKAB\n",
      "sample - dataset: SKAB\n",
      "old data length: 26322\n",
      "new data length: 11137\n",
      "start sample. start time: 1719658066.428162\n",
      "start sample. end time: 1719658074.3853722\n",
      "dataset: SKAB  running time: 7.957210063934326  window_size: 60  sample_num: 100\n",
      "rank : {'PCAAD': 211345368690.99628, 'TCNAE': 206344196436.81345, 'IForestAD': 203253059131.54358, 'NASALSTM': 195088929822.2583, 'TRANAD': 187502182403.82687, 'LSTMVAE': 181111628568.1217, 'DAGMM': 174469359797.91946, 'OmniAnomaly': 173602936129.86856, 'LSTMAE': 162889243689.14725, 'TRANSFORMER': 131682329901.95497, 'UAE': 5477448026.200321}\n",
      "recommending dataset: PMS\n",
      "sample - dataset: PMS\n",
      "old data length: 53122\n",
      "new data length: 34719\n",
      "start sample. start time: 1719658074.8932164\n",
      "start sample. end time: 1719658084.5198596\n",
      "dataset: PMS  running time: 9.626643180847168  window_size: 60  sample_num: 100\n",
      "rank : {'NASALSTM': 125387304267.41202, 'IForestAD': 118241205430.8378, 'DAGMM': 114792402783.19904, 'LSTMVAE': 111876635879.67421, 'OmniAnomaly': 111481916205.71954, 'LSTMAE': 108103320590.28934, 'TRANSFORMER': 102854052722.6133, 'TRANAD': 96788219305.84499, 'TCNAE': 11847865484.283146, 'UAE': 7265077971.652307, 'PCAAD': 2316510139.3240714}\n",
      "recommending dataset: DMDS\n",
      "sample - dataset: DMDS\n",
      "old data length: 200000\n",
      "new data length: 59200\n",
      "start sample. start time: 1719658086.383015\n",
      "start sample. end time: 1719658098.7750661\n",
      "dataset: DMDS  running time: 12.392051219940186  window_size: 60  sample_num: 100\n",
      "rank : {'IForestAD': 1046145214.9882795, 'PCAAD': 997718724.1740277, 'TRANAD': 887421552.6937325, 'LSTMAE': 859216390.1229898, 'OmniAnomaly': 832440183.3684996, 'LSTMVAE': 819998643.9081596, 'TRANSFORMER': 608889181.4484346, 'UAE': 448882870.1155667, 'NASALSTM': 426983705.0397026, 'DAGMM': 184564324.9956553, 'TCNAE': 9003987.924038267}\n",
      "[13.818975448608398, 7.957210063934326, 9.626643180847168, 12.392051219940186]\n"
     ]
    }
   ],
   "source": [
    "compareRuntime(60,100,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e60b8ce6-d626-45ee-b166-d2011dfcda9e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommending dataset: SWAT\n",
      "sample - dataset: SWAT\n",
      "old data length: 155000\n",
      "new data length: 294918\n",
      "start sample. start time: 1719658534.1834843\n",
      "start sample. end time: 1719658553.032073\n",
      "dataset: SWAT  running time: 18.848588705062866  window_size: 120  sample_num: 100\n",
      "rank : {'NASALSTM': 48766277248.97195, 'TRANAD': 46969611672.5451, 'LSTMAE': 45312035194.34856, 'OmniAnomaly': 42675880028.56282, 'IForestAD': 42093330096.3602, 'TRANSFORMER': 40730435751.72938, 'LSTMVAE': 34700121882.01268, 'DAGMM': 33476935804.317604, 'PCAAD': 2906049113.2938895, 'UAE': 750895194.5930206, 'TCNAE': 150243101.08596668}\n",
      "recommending dataset: SKAB\n",
      "sample - dataset: SKAB\n",
      "old data length: 26322\n",
      "new data length: 11137\n",
      "start sample. start time: 1719658553.1797392\n",
      "start sample. end time: 1719658563.1212559\n",
      "dataset: SKAB  running time: 9.941516637802124  window_size: 120  sample_num: 100\n",
      "rank : {'PCAAD': 413476310228.239, 'TCNAE': 411801410912.4646, 'IForestAD': 381273847720.6032, 'NASALSTM': 376704181762.39307, 'TRANAD': 375109667062.1116, 'LSTMVAE': 363487030095.98773, 'OmniAnomaly': 349424804792.726, 'LSTMAE': 325984946176.3708, 'DAGMM': 306870169489.3741, 'TRANSFORMER': 270817329255.8304, 'UAE': 9700003854.67573}\n",
      "recommending dataset: PMS\n",
      "sample - dataset: PMS\n",
      "old data length: 53122\n",
      "new data length: 34719\n",
      "start sample. start time: 1719658564.0480194\n",
      "start sample. end time: 1719658576.866624\n",
      "dataset: PMS  running time: 12.818604707717896  window_size: 120  sample_num: 100\n",
      "rank : {'TCNAE': 541333482515.4247, 'IForestAD': 252739700322.74124, 'NASALSTM': 252108349319.41202, 'LSTMVAE': 234911310995.62665, 'OmniAnomaly': 233480139079.04535, 'DAGMM': 232141361608.71637, 'LSTMAE': 225853670036.17722, 'TRANSFORMER': 208647686607.7569, 'TRANAD': 199911757134.58954, 'UAE': 15530395714.297623, 'PCAAD': 5833215856.887249}\n",
      "recommending dataset: DMDS\n",
      "sample - dataset: DMDS\n",
      "old data length: 200000\n",
      "new data length: 59200\n",
      "start sample. start time: 1719658580.2523854\n",
      "start sample. end time: 1719658596.7102711\n",
      "dataset: DMDS  running time: 16.4578857421875  window_size: 120  sample_num: 100\n",
      "rank : {'NASALSTM': 10063030343.449997, 'OmniAnomaly': 9056397815.987148, 'LSTMAE': 8261191065.017224, 'LSTMVAE': 8062357654.700621, 'TRANAD': 7574081233.619941, 'TRANSFORMER': 6590612645.634716, 'IForestAD': 6314991629.273645, 'PCAAD': 6066074686.992074, 'UAE': 2301724685.7572694, 'TCNAE': 20010569.803567324, 'DAGMM': -8578932297003194.0}\n",
      "[18.848588705062866, 9.941516637802124, 12.818604707717896, 16.4578857421875]\n"
     ]
    }
   ],
   "source": [
    "compareRuntime(120,100,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b86a41f-be9b-4b7d-8108-ea6645fa4d7b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommending dataset: SWAT\n",
      "sample - dataset: SWAT\n",
      "old data length: 155000\n",
      "new data length: 294918\n",
      "start sample. start time: 1719658101.7241843\n",
      "start sample. end time: 1719658105.757632\n",
      "dataset: SWAT  running time: 4.033447742462158  window_size: 30  sample_num: 50\n",
      "rank : {'DAGMM': 7727765784.341623, 'IForestAD': 7386384687.628185, 'NASALSTM': 6999636751.964209, 'TRANAD': 6724650804.231507, 'LSTMAE': 6275101508.819317, 'OmniAnomaly': 6072891460.807126, 'TRANSFORMER': 5673535547.958933, 'LSTMVAE': 4984243524.597024, 'PCAAD': 776294714.4285936, 'UAE': 200957302.97558716, 'TCNAE': 4552483.418600458}\n",
      "recommending dataset: SKAB\n",
      "sample - dataset: SKAB\n",
      "old data length: 26322\n",
      "new data length: 11137\n",
      "start sample. start time: 1719658105.8218186\n",
      "start sample. end time: 1719658108.1277719\n",
      "dataset: SKAB  running time: 2.30595326423645  window_size: 30  sample_num: 50\n",
      "rank : {'PCAAD': 54315365236.022964, 'TCNAE': 53233267624.51654, 'TRANAD': 46218627757.615585, 'IForestAD': 46153907639.98751, 'NASALSTM': 45347105394.44774, 'LSTMVAE': 43903510080.35326, 'OmniAnomaly': 42499728425.517944, 'LSTMAE': 39040610667.39309, 'DAGMM': 37212554159.9715, 'TRANSFORMER': 34282281154.641575, 'UAE': 1163395484.8595648}\n",
      "recommending dataset: PMS\n",
      "sample - dataset: PMS\n",
      "old data length: 53122\n",
      "new data length: 34719\n",
      "start sample. start time: 1719658108.423187\n",
      "start sample. end time: 1719658110.887175\n",
      "dataset: PMS  running time: 2.4639880657196045  window_size: 30  sample_num: 50\n",
      "rank : {'TCNAE': 41629777618.11526, 'IForestAD': 32807040172.827557, 'NASALSTM': 32520898111.997986, 'LSTMVAE': 29652844524.037186, 'OmniAnomaly': 29527756226.414246, 'DAGMM': 29489459976.074066, 'LSTMAE': 28608141212.484283, 'TRANSFORMER': 25195104818.85128, 'TRANAD': 25110422642.94466, 'UAE': 1648199850.6615648, 'PCAAD': 713243675.9210302}\n",
      "recommending dataset: DMDS\n",
      "sample - dataset: DMDS\n",
      "old data length: 200000\n",
      "new data length: 59200\n",
      "start sample. start time: 1719658112.0233417\n",
      "start sample. end time: 1719658116.3757186\n",
      "dataset: DMDS  running time: 4.352376937866211  window_size: 30  sample_num: 50\n",
      "rank : {'NASALSTM': 1855640669.225809, 'OmniAnomaly': 1762594911.6640685, 'LSTMAE': 1477064434.2658992, 'LSTMVAE': 1447888386.4381351, 'PCAAD': 1338266957.0760195, 'TRANAD': 1321574761.373018, 'IForestAD': 1265053208.8928318, 'TRANSFORMER': 1194429407.4766502, 'UAE': 434265946.7444201, 'TCNAE': 2190978.9309729887, 'DAGMM': -1992754250267147.0}\n",
      "[4.033447742462158, 2.30595326423645, 2.4639880657196045, 4.352376937866211]\n"
     ]
    }
   ],
   "source": [
    "compareRuntime(30,50,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af3966ad-81b6-4af2-ad0e-b95ef967c203",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommending dataset: SWAT\n",
      "sample - dataset: SWAT\n",
      "old data length: 155000\n",
      "new data length: 294918\n",
      "start sample. start time: 1719658119.1463757\n",
      "start sample. end time: 1719658129.7795334\n",
      "dataset: SWAT  running time: 10.633157730102539  window_size: 30  sample_num: 100\n",
      "rank : {'DAGMM': 14818442750.044659, 'NASALSTM': 10428434130.978504, 'TRANAD': 9599279706.075548, 'IForestAD': 9441574674.39712, 'LSTMAE': 9011207776.141657, 'OmniAnomaly': 8598374083.912382, 'TRANSFORMER': 7509514236.724902, 'LSTMVAE': 7284438910.755794, 'PCAAD': 222189958.9551606, 'UAE': 155377227.27359945, 'TCNAE': 9117944.518275091}\n",
      "recommending dataset: SKAB\n",
      "sample - dataset: SKAB\n",
      "old data length: 26322\n",
      "new data length: 11137\n",
      "start sample. start time: 1719658129.8382168\n",
      "start sample. end time: 1719658136.9369214\n",
      "dataset: SKAB  running time: 7.09870457649231  window_size: 30  sample_num: 100\n",
      "rank : {'PCAAD': 102030327752.93608, 'TCNAE': 101503622982.50868, 'IForestAD': 98155507740.95752, 'NASALSTM': 97411630565.18414, 'TRANAD': 94794060524.84125, 'LSTMVAE': 91278147743.82143, 'OmniAnomaly': 87867928047.7834, 'DAGMM': 83652508716.10718, 'LSTMAE': 82994460863.10777, 'TRANSFORMER': 66040060108.12763, 'UAE': 2386145991.869096}\n",
      "recommending dataset: PMS\n",
      "sample - dataset: PMS\n",
      "old data length: 53122\n",
      "new data length: 34719\n",
      "start sample. start time: 1719658137.230397\n",
      "start sample. end time: 1719658145.328481\n",
      "dataset: PMS  running time: 8.098083972930908  window_size: 30  sample_num: 100\n",
      "rank : {'TCNAE': 117579010813.38742, 'NASALSTM': 62723747754.92752, 'IForestAD': 61449320811.14895, 'LSTMVAE': 58861386090.60912, 'OmniAnomaly': 58570006795.6129, 'DAGMM': 58015023320.007225, 'LSTMAE': 56562618299.48549, 'TRANSFORMER': 52713045596.40938, 'TRANAD': 49921487005.27729, 'UAE': 2393379555.9334025, 'PCAAD': 1199634420.4397466}\n",
      "recommending dataset: DMDS\n",
      "sample - dataset: DMDS\n",
      "old data length: 200000\n",
      "new data length: 59200\n",
      "start sample. start time: 1719658146.4066296\n",
      "start sample. end time: 1719658156.5939264\n",
      "dataset: DMDS  running time: 10.187296867370605  window_size: 30  sample_num: 100\n",
      "rank : {'IForestAD': 1599946964.4381351, 'OmniAnomaly': 1462036915.4722445, 'NASALSTM': 1400725615.9651005, 'PCAAD': 1302924212.2175045, 'LSTMAE': 1289641540.6673222, 'TRANSFORMER': 1271149156.6585784, 'LSTMVAE': 1260121694.4318342, 'TRANAD': 1219609817.82174, 'UAE': 433167632.1977782, 'TCNAE': 4456719.1521775145, 'DAGMM': -1841621938198045.2}\n",
      "[10.633157730102539, 7.09870457649231, 8.098083972930908, 10.187296867370605]\n"
     ]
    }
   ],
   "source": [
    "compareRuntime(30,100,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e32f05e-37d4-4a56-9d9e-19a29ef2c690",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommending dataset: SWAT\n",
      "sample - dataset: SWAT\n",
      "old data length: 155000\n",
      "new data length: 294918\n",
      "start sample. start time: 1719658706.166537\n",
      "start sample. end time: 1719658727.38955\n",
      "dataset: SWAT  running time: 21.223012924194336  window_size: 30  sample_num: 150\n",
      "rank : {'DAGMM': 16579825753.599308, 'TRANAD': 10572024974.221119, 'LSTMAE': 10293596999.407196, 'OmniAnomaly': 9029841332.268024, 'LSTMVAE': 8744236277.442081, 'IForestAD': 8631966310.509624, 'NASALSTM': 8379477862.634619, 'TRANSFORMER': 7102810975.324599, 'UAE': 134802049.49960035, 'PCAAD': 118107445.39896317, 'TCNAE': 45836673.64351945}\n",
      "recommending dataset: SKAB\n",
      "sample - dataset: SKAB\n",
      "old data length: 26322\n",
      "new data length: 11137\n",
      "start sample. start time: 1719658727.4463546\n",
      "start sample. end time: 1719658742.614192\n",
      "dataset: SKAB  running time: 15.167837381362915  window_size: 30  sample_num: 150\n",
      "rank : {'TCNAE': 158327738146.7699, 'PCAAD': 154466998708.05624, 'NASALSTM': 143363925041.32382, 'IForestAD': 143121576120.2277, 'TRANAD': 142705448542.20987, 'LSTMVAE': 138558885305.827, 'OmniAnomaly': 132323067859.2182, 'LSTMAE': 123804782922.42973, 'DAGMM': 115138143561.9275, 'TRANSFORMER': 101106608477.67299, 'UAE': 3872139775.881847}\n",
      "recommending dataset: PMS\n",
      "sample - dataset: PMS\n",
      "old data length: 53122\n",
      "new data length: 34719\n",
      "start sample. start time: 1719658742.9120064\n",
      "start sample. end time: 1719658760.3358378\n",
      "dataset: PMS  running time: 17.423831462860107  window_size: 30  sample_num: 150\n",
      "rank : {'TCNAE': 147472396868.58554, 'NASALSTM': 95934032265.21947, 'IForestAD': 92341908437.5349, 'DAGMM': 87774185375.44447, 'LSTMVAE': 84678175376.13727, 'OmniAnomaly': 84110031307.35017, 'LSTMAE': 81861190154.92598, 'TRANSFORMER': 78292632697.82256, 'TRANAD': 72436688920.61612, 'UAE': 4978188911.642625, 'PCAAD': 1756501774.9138427}\n",
      "recommending dataset: DMDS\n",
      "sample - dataset: DMDS\n",
      "old data length: 200000\n",
      "new data length: 59200\n",
      "start sample. start time: 1719658761.4644542\n",
      "start sample. end time: 1719658781.3179927\n",
      "dataset: DMDS  running time: 19.853538513183594  window_size: 30  sample_num: 150\n",
      "rank : {'IForestAD': 1887023799.8610575, 'OmniAnomaly': 1668524500.5113082, 'PCAAD': 1586091636.1735175, 'LSTMAE': 1534003790.1521993, 'NASALSTM': 1522000902.7883623, 'LSTMVAE': 1489920356.8186278, 'TRANAD': 1474247526.896808, 'TRANSFORMER': 1466205236.5437055, 'UAE': 551537209.4893343, 'TCNAE': 6707997.1330140615, 'DAGMM': -1920516138666705.0}\n",
      "[21.223012924194336, 15.167837381362915, 17.423831462860107, 19.853538513183594]\n"
     ]
    }
   ],
   "source": [
    "compareRuntime(30,150,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e09adebd-b2bb-4e06-9901-eb3fd47fdfa9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommending dataset: SWAT\n",
      "sample - dataset: SWAT\n",
      "old data length: 155000\n",
      "new data length: 294918\n",
      "start sample. start time: 1719658784.113476\n",
      "start sample. end time: 1719658820.9181669\n",
      "dataset: SWAT  running time: 36.80469083786011  window_size: 30  sample_num: 200\n",
      "rank : {'DAGMM': 30269531554.825886, 'NASALSTM': 25083804983.90277, 'TRANAD': 22950909079.14804, 'IForestAD': 22495068800.30727, 'LSTMAE': 22026090256.043156, 'OmniAnomaly': 20764972678.948856, 'TRANSFORMER': 19058363876.516357, 'LSTMVAE': 17166651012.449955, 'PCAAD': 1177261395.9340146, 'UAE': 436986147.6231437, 'TCNAE': 31687486.904341646}\n",
      "recommending dataset: SKAB\n",
      "sample - dataset: SKAB\n",
      "old data length: 26322\n",
      "new data length: 11137\n",
      "start sample. start time: 1719658820.976197\n",
      "start sample. end time: 1719658847.6054153\n",
      "dataset: SKAB  running time: 26.629218339920044  window_size: 30  sample_num: 200\n",
      "rank : {'TCNAE': 204338036649.983, 'PCAAD': 197511861073.21292, 'IForestAD': 193846021422.64114, 'NASALSTM': 190608844682.52725, 'TRANAD': 188033740516.58997, 'LSTMVAE': 182755698474.38895, 'OmniAnomaly': 175075228524.2514, 'LSTMAE': 165109478686.9799, 'DAGMM': 157148321734.30054, 'TRANSFORMER': 129232045406.2005, 'UAE': 4782504948.436628}\n",
      "recommending dataset: PMS\n",
      "sample - dataset: PMS\n",
      "old data length: 53122\n",
      "new data length: 34719\n",
      "start sample. start time: 1719658847.9129677\n",
      "start sample. end time: 1719658878.3502548\n",
      "dataset: PMS  running time: 30.437287092208862  window_size: 30  sample_num: 200\n",
      "rank : {'TCNAE': 236998655545.7535, 'NASALSTM': 127248718688.20894, 'IForestAD': 125621748626.87561, 'DAGMM': 118313295926.19272, 'LSTMVAE': 116468426977.38147, 'OmniAnomaly': 115718572501.16414, 'LSTMAE': 111879410772.53886, 'TRANSFORMER': 104458196177.00104, 'TRANAD': 98182730292.21841, 'UAE': 6159204728.304487, 'PCAAD': 2701453274.1540866}\n",
      "recommending dataset: DMDS\n",
      "sample - dataset: DMDS\n",
      "old data length: 200000\n",
      "new data length: 59200\n",
      "start sample. start time: 1719658879.4679472\n",
      "start sample. end time: 1719658912.5989149\n",
      "dataset: DMDS  running time: 33.13096761703491  window_size: 30  sample_num: 200\n",
      "rank : {'OmniAnomaly': 2405263965.6235623, 'LSTMAE': 2176468397.3621674, 'LSTMVAE': 2105948926.2371154, 'TRANAD': 2035325706.6686935, 'IForestAD': 1892211134.1865687, 'PCAAD': 1658420926.4601812, 'NASALSTM': 1507346259.329245, 'TRANSFORMER': 1146981204.153915, 'UAE': 679628368.7314535, 'TCNAE': 8959066.465199538, 'DAGMM': -1626578140392445.2}\n",
      "[36.80469083786011, 26.629218339920044, 30.437287092208862, 33.13096761703491]\n"
     ]
    }
   ],
   "source": [
    "compareRuntime(30,200,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "70798248-6b2e-4546-9c64-e52eca395181",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommending dataset: SWAT\n",
      "sample - dataset: SWAT\n",
      "old data length: 155000\n",
      "new data length: 294918\n",
      "start sample. start time: 1719658980.2252874\n",
      "start sample. end time: 1719659035.0363603\n",
      "dataset: SWAT  running time: 54.8110728263855  window_size: 30  sample_num: 250\n",
      "rank : {'TRANAD': 24286311832.59969, 'DAGMM': 24040545600.95054, 'NASALSTM': 23462782929.850517, 'LSTMAE': 23348654974.11821, 'OmniAnomaly': 21555806750.74443, 'IForestAD': 20795109559.562912, 'TRANSFORMER': 19344504737.931404, 'LSTMVAE': 18645378612.13691, 'PCAAD': 831355470.8690671, 'UAE': 400770599.8390877, 'TCNAE': 94211734.48910958}\n",
      "recommending dataset: SKAB\n",
      "sample - dataset: SKAB\n",
      "old data length: 26322\n",
      "new data length: 11137\n",
      "start sample. start time: 1719659035.099544\n",
      "start sample. end time: 1719659076.231439\n",
      "dataset: SKAB  running time: 41.13189506530762  window_size: 30  sample_num: 250\n",
      "rank : {'PCAAD': 270713771273.68445, 'TCNAE': 268755363867.7518, 'IForestAD': 246335050602.67975, 'NASALSTM': 244339042094.30017, 'TRANAD': 242158681182.92584, 'LSTMVAE': 233704772468.497, 'OmniAnomaly': 224090207205.9251, 'LSTMAE': 211240149656.9017, 'DAGMM': 200957073227.55237, 'TRANSFORMER': 165616606323.3447, 'UAE': 6774810221.91509}\n",
      "recommending dataset: PMS\n",
      "sample - dataset: PMS\n",
      "old data length: 53122\n",
      "new data length: 34719\n",
      "start sample. start time: 1719659076.5303113\n",
      "start sample. end time: 1719659123.5906076\n",
      "dataset: PMS  running time: 47.060296297073364  window_size: 30  sample_num: 250\n",
      "rank : {'NASALSTM': 165122537041.63266, 'IForestAD': 153799601936.0839, 'TCNAE': 152951220049.45572, 'DAGMM': 143789222102.69922, 'LSTMVAE': 141100356585.5904, 'OmniAnomaly': 139898453694.97382, 'LSTMAE': 138272998153.47937, 'TRANSFORMER': 134838755024.589, 'TRANAD': 124104891380.62242, 'UAE': 10390088749.026236, 'PCAAD': 3885103284.1080413}\n",
      "recommending dataset: DMDS\n",
      "sample - dataset: DMDS\n",
      "old data length: 200000\n",
      "new data length: 59200\n",
      "start sample. start time: 1719659124.6841261\n",
      "start sample. end time: 1719659174.9132004\n",
      "dataset: DMDS  running time: 50.229074239730835  window_size: 30  sample_num: 250\n",
      "rank : {'IForestAD': 2441445255.077588, 'NASALSTM': 2209093646.789314, 'OmniAnomaly': 2202292438.306387, 'LSTMAE': 1947741783.2815714, 'LSTMVAE': 1897805409.8822458, 'TRANAD': 1881185911.7108662, 'PCAAD': 1796251606.0866983, 'TRANSFORMER': 1402065918.0450768, 'UAE': 830059057.9435867, 'TCNAE': 11196478.614757977, 'DAGMM': -1681692053510656.0}\n",
      "[54.8110728263855, 41.13189506530762, 47.060296297073364, 50.229074239730835]\n"
     ]
    }
   ],
   "source": [
    "compareRuntime(30,250,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5986df7-fe09-4d10-b98c-acfa5b2723a1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommending dataset: SWAT\n",
      "sample - dataset: SWAT\n",
      "old data length: 155000\n",
      "new data length: 294918\n",
      "start sample. start time: 1719658236.756129\n",
      "start sample. end time: 1719658247.078709\n",
      "dataset: SWAT  running time: 10.322579860687256  window_size: 30  sample_num: 100\n",
      "rank : {'DAGMM': 2043058665.4879045, 'TRANAD': 1693285308.3028655, 'LSTMAE': 1611009258.0884435, 'LSTMVAE': 1419634583.5046055, 'OmniAnomaly': 1403568962.9804344, 'IForestAD': 1355426398.5083768, 'NASALSTM': 1147002142.1886914, 'TRANSFORMER': 1046432643.5362458, 'UAE': 17607464.08379796, 'PCAAD': 16135169.79479244, 'TCNAE': 2443271.218714638}\n",
      "recommending dataset: SKAB\n",
      "sample - dataset: SKAB\n",
      "old data length: 26322\n",
      "new data length: 11137\n",
      "start sample. start time: 1719658247.136587\n",
      "start sample. end time: 1719658254.1930597\n",
      "dataset: SKAB  running time: 7.0564727783203125  window_size: 30  sample_num: 100\n",
      "rank : {'PCAAD': 51779725545.830185, 'IForestAD': 51552953288.72378, 'NASALSTM': 48682415431.81259, 'TCNAE': 48016469137.63058, 'TRANAD': 46795114867.98774, 'LSTMVAE': 45595812541.30644, 'DAGMM': 45286999836.309044, 'OmniAnomaly': 43792955363.79602, 'LSTMAE': 41228835183.09021, 'TRANSFORMER': 32725273286.756622, 'UAE': 1337982526.246441}\n",
      "recommending dataset: PMS\n",
      "sample - dataset: PMS\n",
      "old data length: 53122\n",
      "new data length: 34719\n",
      "start sample. start time: 1719658254.489108\n",
      "start sample. end time: 1719658262.4611886\n",
      "dataset: PMS  running time: 7.97208046913147  window_size: 30  sample_num: 100\n",
      "rank : {'NASALSTM': 62724577382.16834, 'IForestAD': 61293589716.84641, 'DAGMM': 57960141496.17923, 'LSTMVAE': 56170135862.601105, 'OmniAnomaly': 55760380184.914764, 'LSTMAE': 53628534735.47982, 'TRANSFORMER': 52466491515.72204, 'TRANAD': 48083989847.7865, 'TCNAE': 8818612275.742477, 'UAE': 2755607216.6319942, 'PCAAD': 1043537423.3398277}\n",
      "recommending dataset: DMDS\n",
      "sample - dataset: DMDS\n",
      "old data length: 200000\n",
      "new data length: 59200\n",
      "start sample. start time: 1719658263.5798502\n",
      "start sample. end time: 1719658273.5812786\n",
      "dataset: DMDS  running time: 10.001428365707397  window_size: 30  sample_num: 100\n",
      "rank : {'NASALSTM': 177053992.08721867, 'OmniAnomaly': 158166559.34598848, 'LSTMAE': 144899841.9443038, 'LSTMVAE': 141561668.0587456, 'TRANAD': 134136527.74548091, 'IForestAD': 118395901.00270218, 'TRANSFORMER': 107970763.47691667, 'PCAAD': 63897038.55373896, 'UAE': 41888310.46679895, 'TCNAE': 404902.28573405015, 'DAGMM': -146070274979448.84}\n",
      "[10.322579860687256, 7.0564727783203125, 7.97208046913147, 10.001428365707397]\n"
     ]
    }
   ],
   "source": [
    "compareRuntime(30,100,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1fda87a5-b970-4778-abed-7d59511d985e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommending dataset: SWAT\n",
      "sample - dataset: SWAT\n",
      "old data length: 155000\n",
      "new data length: 294918\n",
      "start sample. start time: 1719658276.3482707\n",
      "start sample. end time: 1719658286.8291264\n",
      "dataset: SWAT  running time: 10.480855703353882  window_size: 30  sample_num: 100\n",
      "rank : {'DAGMM': 871657.0459106455, 'NASALSTM': 606911.0673924898, 'IForestAD': 560303.7783216538, 'TRANAD': 544043.5722322428, 'LSTMAE': 514429.46145990636, 'OmniAnomaly': 494839.9926988435, 'TRANSFORMER': 434898.8201384912, 'LSTMVAE': 402025.90602118516, 'PCAAD': 23177.338022526044, 'UAE': 9639.063090292608, 'TCNAE': 3098.2679219316387}\n",
      "recommending dataset: SKAB\n",
      "sample - dataset: SKAB\n",
      "old data length: 26322\n",
      "new data length: 11137\n",
      "start sample. start time: 1719658286.885687\n",
      "start sample. end time: 1719658294.1203895\n",
      "dataset: SKAB  running time: 7.2347023487091064  window_size: 30  sample_num: 100\n",
      "rank : {'PCAAD': 108620678926.68321, 'TCNAE': 106893793648.73833, 'NASALSTM': 99187338627.00949, 'IForestAD': 98879244138.7576, 'TRANAD': 95557873027.3091, 'LSTMVAE': 91734716684.43877, 'OmniAnomaly': 88213365663.68625, 'DAGMM': 87474875933.60832, 'LSTMAE': 83251701698.46747, 'TRANSFORMER': 64714897694.41042, 'UAE': 2480874649.965442}\n",
      "recommending dataset: PMS\n",
      "sample - dataset: PMS\n",
      "old data length: 53122\n",
      "new data length: 34719\n",
      "start sample. start time: 1719658294.4179716\n",
      "start sample. end time: 1719658302.473772\n",
      "dataset: PMS  running time: 8.055800437927246  window_size: 30  sample_num: 100\n",
      "rank : {'TCNAE': 144414148701.8833, 'NASALSTM': 64538366811.79378, 'IForestAD': 62938068799.265305, 'LSTMVAE': 59334935944.70913, 'OmniAnomaly': 58887938014.073296, 'DAGMM': 57762025669.53495, 'LSTMAE': 57685569268.49597, 'TRANSFORMER': 54401077931.90491, 'TRANAD': 50945484293.15619, 'UAE': 3159547158.0850105, 'PCAAD': 1322999493.0259218}\n",
      "recommending dataset: DMDS\n",
      "sample - dataset: DMDS\n",
      "old data length: 200000\n",
      "new data length: 59200\n",
      "start sample. start time: 1719658303.5700076\n",
      "start sample. end time: 1719658313.8327217\n",
      "dataset: DMDS  running time: 10.262714147567749  window_size: 30  sample_num: 100\n",
      "rank : {'IForestAD': 524585214.80581176, 'PCAAD': 499155970.5362594, 'TRANAD': 449471965.39611626, 'LSTMAE': 435092575.74636704, 'OmniAnomaly': 419485773.11852235, 'LSTMVAE': 415249894.1524424, 'TRANSFORMER': 309896963.9312069, 'UAE': 224224324.7507426, 'NASALSTM': 219342722.07452577, 'DAGMM': 90981587.59714001, 'TCNAE': 4498240.892433652}\n",
      "[10.480855703353882, 7.2347023487091064, 8.055800437927246, 10.262714147567749]\n"
     ]
    }
   ],
   "source": [
    "compareRuntime(30,100,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cf6e8a6a-1800-4fc5-b8b9-c1e3461c037b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommending dataset: SWAT\n",
      "sample - dataset: SWAT\n",
      "old data length: 155000\n",
      "new data length: 294918\n",
      "start sample. start time: 1719658316.6526926\n",
      "start sample. end time: 1719658327.1589737\n",
      "dataset: SWAT  running time: 10.50628113746643  window_size: 30  sample_num: 100\n",
      "rank : {'DAGMM': 16250499655.0955, 'NASALSTM': 10987768043.059027, 'TRANAD': 10337945415.221573, 'LSTMAE': 9997987151.370258, 'IForestAD': 9622590786.386978, 'OmniAnomaly': 9272785595.95234, 'TRANSFORMER': 8240510046.486, 'LSTMVAE': 7831869817.751213, 'PCAAD': 470393577.04231524, 'UAE': 176558181.21021038, 'TCNAE': 9147733.679836221}\n",
      "recommending dataset: SKAB\n",
      "sample - dataset: SKAB\n",
      "old data length: 26322\n",
      "new data length: 11137\n",
      "start sample. start time: 1719658327.2173345\n",
      "start sample. end time: 1719658334.276241\n",
      "dataset: SKAB  running time: 7.058906555175781  window_size: 30  sample_num: 100\n",
      "rank : {'PCAAD': 104902823094.83214, 'TCNAE': 103915919226.75194, 'IForestAD': 99238161217.33371, 'NASALSTM': 96718901308.97609, 'TRANAD': 95708363190.0081, 'LSTMVAE': 92664393941.9637, 'OmniAnomaly': 89295394157.03452, 'LSTMAE': 84177863016.6017, 'DAGMM': 79653795296.00066, 'TRANSFORMER': 65579518371.24536, 'UAE': 2385113190.838344}\n",
      "recommending dataset: PMS\n",
      "sample - dataset: PMS\n",
      "old data length: 53122\n",
      "new data length: 34719\n",
      "start sample. start time: 1719658334.5800905\n",
      "start sample. end time: 1719658342.6702034\n",
      "dataset: PMS  running time: 8.090112924575806  window_size: 30  sample_num: 100\n",
      "rank : {'TCNAE': 121520029080.30983, 'NASALSTM': 63851804117.90854, 'IForestAD': 62130071198.54594, 'LSTMVAE': 58410929412.743126, 'OmniAnomaly': 58148340454.30697, 'DAGMM': 56839948610.896416, 'LSTMAE': 56656543612.535706, 'TRANSFORMER': 52174753000.2109, 'TRANAD': 49943565030.06607, 'UAE': 4238217363.429664, 'PCAAD': 1426154590.1527834}\n",
      "recommending dataset: DMDS\n",
      "sample - dataset: DMDS\n",
      "old data length: 200000\n",
      "new data length: 59200\n",
      "start sample. start time: 1719658343.772894\n",
      "start sample. end time: 1719658353.979124\n",
      "dataset: DMDS  running time: 10.206230163574219  window_size: 30  sample_num: 100\n",
      "rank : {'IForestAD': 1598367994.4803166, 'OmniAnomaly': 1448974068.8960721, 'NASALSTM': 1399894058.768959, 'PCAAD': 1298857199.1927476, 'LSTMAE': 1276137829.6951332, 'TRANSFORMER': 1250825401.2080991, 'LSTMVAE': 1247869698.8916574, 'TRANAD': 1204664226.0464404, 'UAE': 428819655.50621265, 'TCNAE': 4456980.10564095, 'DAGMM': -1794222309477607.8}\n",
      "[10.50628113746643, 7.058906555175781, 8.090112924575806, 10.206230163574219]\n"
     ]
    }
   ],
   "source": [
    "compareRuntime(30,100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e61f9e-65fa-4100-a1fb-c1c7697f9d37",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d4ca1f-db72-474a-8897-bfb25ef3c27c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}